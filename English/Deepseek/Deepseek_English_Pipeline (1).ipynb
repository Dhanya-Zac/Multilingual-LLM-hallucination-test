{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a035d8009c04f99bbdfc8297028402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96b4bfa895fe4269bba3afd916bbdb84",
              "IPY_MODEL_c4413d4981c5414d98e7743314ce39cc",
              "IPY_MODEL_b71921e4de10454f9dcc59318e15c858"
            ],
            "layout": "IPY_MODEL_f31a8d66ffe74f2095d6ed509e010a06"
          }
        },
        "96b4bfa895fe4269bba3afd916bbdb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec30f7ef7ac42ecbe19c0189ed0a2d2",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5ed4525dd04d25928c1a351b03d05f",
            "value": "tokenizer_config.json: "
          }
        },
        "c4413d4981c5414d98e7743314ce39cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e725e48f69c4aa1871980408303dd72",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b075b23e8a9146aa98c1ef9d626a35c0",
            "value": 1
          }
        },
        "b71921e4de10454f9dcc59318e15c858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e839338e1f74093af2091827d816488",
            "placeholder": "​",
            "style": "IPY_MODEL_3976e8e1d49d48649c18ffd8e995258b",
            "value": " 3.13k/? [00:00&lt;00:00, 201kB/s]"
          }
        },
        "f31a8d66ffe74f2095d6ed509e010a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec30f7ef7ac42ecbe19c0189ed0a2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5ed4525dd04d25928c1a351b03d05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e725e48f69c4aa1871980408303dd72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b075b23e8a9146aa98c1ef9d626a35c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e839338e1f74093af2091827d816488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3976e8e1d49d48649c18ffd8e995258b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3d60a9a35b34f93aa4590f148817395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fecb95627e6c42609ef64d4fb7187c92",
              "IPY_MODEL_867fe34d8d654b55ab125954b2d44b22",
              "IPY_MODEL_1ef7e2c00ae645e093125ab925324c26"
            ],
            "layout": "IPY_MODEL_0b9fcf15ef8b4f9aac08660afa489af5"
          }
        },
        "fecb95627e6c42609ef64d4fb7187c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aad37eb126340e9a859940370d0078e",
            "placeholder": "​",
            "style": "IPY_MODEL_8deb313d53ae486a8809817a3d42e832",
            "value": "tokenizer.json: "
          }
        },
        "867fe34d8d654b55ab125954b2d44b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1820394bb35c4af188c237937e1c1f53",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6060c8fe46e41d3b7f82f12fba36fd7",
            "value": 1
          }
        },
        "1ef7e2c00ae645e093125ab925324c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8be851278574953936d69e7625ff89b",
            "placeholder": "​",
            "style": "IPY_MODEL_067126b8f9074c66ac05faf49af7058b",
            "value": " 7.85M/? [00:00&lt;00:00, 116MB/s]"
          }
        },
        "0b9fcf15ef8b4f9aac08660afa489af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aad37eb126340e9a859940370d0078e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8deb313d53ae486a8809817a3d42e832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1820394bb35c4af188c237937e1c1f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e6060c8fe46e41d3b7f82f12fba36fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8be851278574953936d69e7625ff89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067126b8f9074c66ac05faf49af7058b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9595cda2d9d43c5b43653eae73e2523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f86d6e812274e8e8cad31ca74994356",
              "IPY_MODEL_14c77048d51848fa84da3a2498c81a4a",
              "IPY_MODEL_6b4f6262a6b94b1faddc9eb562bb39a8"
            ],
            "layout": "IPY_MODEL_c744e40a060b43eaa168964742608a1f"
          }
        },
        "0f86d6e812274e8e8cad31ca74994356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b20d29906142b8b04c0ce6ce72f0f5",
            "placeholder": "​",
            "style": "IPY_MODEL_c2e4fa88ef16449c8a17f51330f1b43c",
            "value": "modules.json: 100%"
          }
        },
        "14c77048d51848fa84da3a2498c81a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8cb862dc8a41edb2b8136225bf57cc",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9348445209d74e5a9a41dfbcebd1eb39",
            "value": 349
          }
        },
        "6b4f6262a6b94b1faddc9eb562bb39a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef6f7577bbb43ec9523ad0af20332f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e278ed95364205a70c308469a8a3fa",
            "value": " 349/349 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "c744e40a060b43eaa168964742608a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b20d29906142b8b04c0ce6ce72f0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e4fa88ef16449c8a17f51330f1b43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8cb862dc8a41edb2b8136225bf57cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9348445209d74e5a9a41dfbcebd1eb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ef6f7577bbb43ec9523ad0af20332f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e278ed95364205a70c308469a8a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c0fe2d3e99345dca1a49e7cb813401a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebd777b3fee140c88ce8bcddb374b98d",
              "IPY_MODEL_5fffc3dcb18f4d88a52c28cd8eda3e56",
              "IPY_MODEL_8ae91fe418ba478cb616bcae97b6b66f"
            ],
            "layout": "IPY_MODEL_67d1e1592de943cfb2f2059e81d69ec2"
          }
        },
        "ebd777b3fee140c88ce8bcddb374b98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db8011f3f795487e8236efcc7b16bd26",
            "placeholder": "​",
            "style": "IPY_MODEL_575b179a41504f85a0cede8df7d9582a",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "5fffc3dcb18f4d88a52c28cd8eda3e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23119b3d94ef4bd487cd6cabf0628306",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96ceb4d4bc4d4c78b77d69af4aa9831f",
            "value": 116
          }
        },
        "8ae91fe418ba478cb616bcae97b6b66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c4a30174dd47bab92a74f6cbb5767c",
            "placeholder": "​",
            "style": "IPY_MODEL_b39bad47d9b5487a8089365c1f70a8e9",
            "value": " 116/116 [00:00&lt;00:00, 8.17kB/s]"
          }
        },
        "67d1e1592de943cfb2f2059e81d69ec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db8011f3f795487e8236efcc7b16bd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575b179a41504f85a0cede8df7d9582a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23119b3d94ef4bd487cd6cabf0628306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ceb4d4bc4d4c78b77d69af4aa9831f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66c4a30174dd47bab92a74f6cbb5767c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39bad47d9b5487a8089365c1f70a8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cfb93664484485cb21eb72c7a37bd6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c565cfcc426b477d8d3ce5a230808663",
              "IPY_MODEL_e8c146f817154cb58d791490c65ae40e",
              "IPY_MODEL_3ac557902ea44c23b9e8b6c27e04546e"
            ],
            "layout": "IPY_MODEL_9bdd9f4b64b849ba9504023df7085c51"
          }
        },
        "c565cfcc426b477d8d3ce5a230808663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea5dad8b4f844568144f351071b3940",
            "placeholder": "​",
            "style": "IPY_MODEL_f2089f8e763d4203950bdd4e233c036a",
            "value": "README.md: "
          }
        },
        "e8c146f817154cb58d791490c65ae40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2331c524f56406aaf7f3e1813f1fc73",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fd57b8183f748769894ae8927438a51",
            "value": 1
          }
        },
        "3ac557902ea44c23b9e8b6c27e04546e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfde57cb585041b8ae183ee76e9314cf",
            "placeholder": "​",
            "style": "IPY_MODEL_5e29edf2e3a44604818838a69e67cdde",
            "value": " 10.5k/? [00:00&lt;00:00, 742kB/s]"
          }
        },
        "9bdd9f4b64b849ba9504023df7085c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea5dad8b4f844568144f351071b3940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2089f8e763d4203950bdd4e233c036a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2331c524f56406aaf7f3e1813f1fc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1fd57b8183f748769894ae8927438a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfde57cb585041b8ae183ee76e9314cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e29edf2e3a44604818838a69e67cdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c49c3fc8f67408e85673da5b2a33ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e874acf68744ed1bfce21a77a9fc0e9",
              "IPY_MODEL_52b03d325ce34c47a02610c4ddaa6e40",
              "IPY_MODEL_0e58f6a54b7d4bd9bb8c6ac9a00e6555"
            ],
            "layout": "IPY_MODEL_dcd38004ce294a488e556e2cc6d57c1d"
          }
        },
        "1e874acf68744ed1bfce21a77a9fc0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c940cc70d0f541229b8a1398292fbf7e",
            "placeholder": "​",
            "style": "IPY_MODEL_c8aa32737967472991ad4d617cc6bdb1",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "52b03d325ce34c47a02610c4ddaa6e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61e75e318e34457c8aea1723b7a95c14",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d35538c511b548408a918d56eff1fbde",
            "value": 53
          }
        },
        "0e58f6a54b7d4bd9bb8c6ac9a00e6555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc6285fac244a9283e8629ec2775969",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6359925e354f70a6ba922adc110dc8",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.00kB/s]"
          }
        },
        "dcd38004ce294a488e556e2cc6d57c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c940cc70d0f541229b8a1398292fbf7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8aa32737967472991ad4d617cc6bdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e75e318e34457c8aea1723b7a95c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d35538c511b548408a918d56eff1fbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc6285fac244a9283e8629ec2775969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6359925e354f70a6ba922adc110dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88732b96d50d4b6d9d7e20438e5f3228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e70dad8ade744ee3b219f003704236b7",
              "IPY_MODEL_d4cbdfb17e164cbdb4ef3a12a5e7f56f",
              "IPY_MODEL_e91e0d22a2c74c8f8f0c599408f36f25"
            ],
            "layout": "IPY_MODEL_0f771ad6c9164be59642b1ebc9640f14"
          }
        },
        "e70dad8ade744ee3b219f003704236b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd29591d86a8461b987709a53d26bd42",
            "placeholder": "​",
            "style": "IPY_MODEL_0df71ede422a44b29eaedae8202647fb",
            "value": "config.json: 100%"
          }
        },
        "d4cbdfb17e164cbdb4ef3a12a5e7f56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3813838450644659c1cc2440a732407",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9816c88013e4519966c433ed6c68277",
            "value": 612
          }
        },
        "e91e0d22a2c74c8f8f0c599408f36f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a6110408b84796aba35fab86ebc1fd",
            "placeholder": "​",
            "style": "IPY_MODEL_ed3fac99dd72450680083120e5019651",
            "value": " 612/612 [00:00&lt;00:00, 41.3kB/s]"
          }
        },
        "0f771ad6c9164be59642b1ebc9640f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd29591d86a8461b987709a53d26bd42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df71ede422a44b29eaedae8202647fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3813838450644659c1cc2440a732407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9816c88013e4519966c433ed6c68277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46a6110408b84796aba35fab86ebc1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed3fac99dd72450680083120e5019651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7978a9ffa17f47e1b4fca3dcf66b1c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af78f1e2f4ea489381f5f207ca0c54d6",
              "IPY_MODEL_96adbdff6da748539546f1738353b98c",
              "IPY_MODEL_d1c9ffcd3032480bb279b55f067fc4bb"
            ],
            "layout": "IPY_MODEL_aa813a9c9a544898b3104b68e572d754"
          }
        },
        "af78f1e2f4ea489381f5f207ca0c54d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a5eab9e32d4c20a35f1f84d84346a2",
            "placeholder": "​",
            "style": "IPY_MODEL_aefa848e83094e2c8b7fa367aa31f229",
            "value": "model.safetensors: 100%"
          }
        },
        "96adbdff6da748539546f1738353b98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d3bafeeb6143a4ad03e26c61f101ae",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1d829d7aaa24726a5d322831df2fd0c",
            "value": 90868376
          }
        },
        "d1c9ffcd3032480bb279b55f067fc4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76cedef3ccae467fbbb8ada31979a87f",
            "placeholder": "​",
            "style": "IPY_MODEL_bc993e01fbf7464d8a1449552f69707d",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 131MB/s]"
          }
        },
        "aa813a9c9a544898b3104b68e572d754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a5eab9e32d4c20a35f1f84d84346a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aefa848e83094e2c8b7fa367aa31f229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74d3bafeeb6143a4ad03e26c61f101ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d829d7aaa24726a5d322831df2fd0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76cedef3ccae467fbbb8ada31979a87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc993e01fbf7464d8a1449552f69707d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9e9d6d60f244f2dade5c25652816cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d324b5d66244f4cbfd8af3cafdeee7f",
              "IPY_MODEL_c10f795d4dae4d8b822638bc1bc34c17",
              "IPY_MODEL_98cfff1fa2304a44944aaf3de932b93a"
            ],
            "layout": "IPY_MODEL_8bff5546654e49f5a342adaad9d390b2"
          }
        },
        "3d324b5d66244f4cbfd8af3cafdeee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffe9c969953646b0a485335ee073dcbf",
            "placeholder": "​",
            "style": "IPY_MODEL_805d67180c514ac08ee0c1c8a6de9cad",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c10f795d4dae4d8b822638bc1bc34c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c7e48f09eea46a089f5cd8a4721e188",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2463ea86eb6e48a5a80c3deece3010dd",
            "value": 350
          }
        },
        "98cfff1fa2304a44944aaf3de932b93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6cddcb363a34ad39b901b1a1c44036a",
            "placeholder": "​",
            "style": "IPY_MODEL_1aebf18c6e454679b967d5fbe6b027e7",
            "value": " 350/350 [00:00&lt;00:00, 29.9kB/s]"
          }
        },
        "8bff5546654e49f5a342adaad9d390b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe9c969953646b0a485335ee073dcbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805d67180c514ac08ee0c1c8a6de9cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c7e48f09eea46a089f5cd8a4721e188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2463ea86eb6e48a5a80c3deece3010dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6cddcb363a34ad39b901b1a1c44036a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aebf18c6e454679b967d5fbe6b027e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc07a0b94c3e4888b55ac8ee49ce7fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13512096ad7b422a9bc6e0f5fd4e33b2",
              "IPY_MODEL_4175ac14c76b4191aa8f71bcc235dd3e",
              "IPY_MODEL_46ed76b410ae4772908a5c12817d1403"
            ],
            "layout": "IPY_MODEL_6c87ab7702904f3caf1546e9cc7d6336"
          }
        },
        "13512096ad7b422a9bc6e0f5fd4e33b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e361925f474bc989bf793a42875055",
            "placeholder": "​",
            "style": "IPY_MODEL_edf39035dd974638b8f55c6ccf527408",
            "value": "vocab.txt: "
          }
        },
        "4175ac14c76b4191aa8f71bcc235dd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce79286f63944578f71ab2facf95dd8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12443127e3324b56a58d423a39188dad",
            "value": 1
          }
        },
        "46ed76b410ae4772908a5c12817d1403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5bca298be04f75bbb480e9c721d1d8",
            "placeholder": "​",
            "style": "IPY_MODEL_5e41fb7a946447aaa24ef3977ecae8a9",
            "value": " 232k/? [00:00&lt;00:00, 8.06MB/s]"
          }
        },
        "6c87ab7702904f3caf1546e9cc7d6336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e361925f474bc989bf793a42875055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf39035dd974638b8f55c6ccf527408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce79286f63944578f71ab2facf95dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "12443127e3324b56a58d423a39188dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa5bca298be04f75bbb480e9c721d1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e41fb7a946447aaa24ef3977ecae8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83fb9e27161e45a083c13fedc49f6d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28ee53dade944080bc3bce964b9e3efb",
              "IPY_MODEL_1ff71411b33244b9a2ce0c86375fc0a4",
              "IPY_MODEL_fbc8225612d149f59d21c9511b48afcf"
            ],
            "layout": "IPY_MODEL_62baaf11d6314484a4d92343e56b3df1"
          }
        },
        "28ee53dade944080bc3bce964b9e3efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f1977009e664f90abed5282b4c7ada4",
            "placeholder": "​",
            "style": "IPY_MODEL_6ad89d8366e049f08d20b10dcc310b90",
            "value": "tokenizer.json: "
          }
        },
        "1ff71411b33244b9a2ce0c86375fc0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569497dc02dd45a7ac44cbbfa6f1085d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17da9ea36f504633b5c235933af379fa",
            "value": 1
          }
        },
        "fbc8225612d149f59d21c9511b48afcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_285d4dbea03f4528927fb61c38153be6",
            "placeholder": "​",
            "style": "IPY_MODEL_e372bcb94c1f43898e56e87f4faed2ca",
            "value": " 466k/? [00:00&lt;00:00, 19.3MB/s]"
          }
        },
        "62baaf11d6314484a4d92343e56b3df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f1977009e664f90abed5282b4c7ada4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ad89d8366e049f08d20b10dcc310b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "569497dc02dd45a7ac44cbbfa6f1085d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "17da9ea36f504633b5c235933af379fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "285d4dbea03f4528927fb61c38153be6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e372bcb94c1f43898e56e87f4faed2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abc3f840f5c648cb88fd2209ce53f155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0c61d03d6714544b12f3fa768dbe669",
              "IPY_MODEL_937b1d63fb014044bbc34d8384e194db",
              "IPY_MODEL_12dcd76ceb3c4168b76f1d338a8f73dc"
            ],
            "layout": "IPY_MODEL_57779c4934df45a191b2c7215e4e4bae"
          }
        },
        "c0c61d03d6714544b12f3fa768dbe669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55dcad96dfc4473b807c677564bd0521",
            "placeholder": "​",
            "style": "IPY_MODEL_608d7dcb76c64bea9ec496bf17b0e231",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "937b1d63fb014044bbc34d8384e194db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd3d0295eba4af1918380453f5d0b8f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2c94d4568db447d963fe9b1b6ef4b39",
            "value": 112
          }
        },
        "12dcd76ceb3c4168b76f1d338a8f73dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92bce7144c3444db8063320adb29711",
            "placeholder": "​",
            "style": "IPY_MODEL_09916180f51844a1860fb3942b3be037",
            "value": " 112/112 [00:00&lt;00:00, 8.63kB/s]"
          }
        },
        "57779c4934df45a191b2c7215e4e4bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55dcad96dfc4473b807c677564bd0521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608d7dcb76c64bea9ec496bf17b0e231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecd3d0295eba4af1918380453f5d0b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c94d4568db447d963fe9b1b6ef4b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b92bce7144c3444db8063320adb29711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09916180f51844a1860fb3942b3be037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa749a91d3d34135a7d02d8cc972ce8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cfca78076b34a18b61ec3ac17514226",
              "IPY_MODEL_36a246ea03b6474b8613f7b01351e05b",
              "IPY_MODEL_84aae3c9f85343a4b69c102e533a1389"
            ],
            "layout": "IPY_MODEL_d2d6802b498343edaaff8216bf1289ed"
          }
        },
        "1cfca78076b34a18b61ec3ac17514226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56b45fd0f16546d288873ef4734a0b45",
            "placeholder": "​",
            "style": "IPY_MODEL_4e0a62c6dfd94950aae036a34759243b",
            "value": "config.json: 100%"
          }
        },
        "36a246ea03b6474b8613f7b01351e05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a523ff43c64a448a053828e8fe2b44",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6ef3c0ebd634b129534d1425cab3f3d",
            "value": 190
          }
        },
        "84aae3c9f85343a4b69c102e533a1389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc5ea2a635e3481ba3ad13dc05896051",
            "placeholder": "​",
            "style": "IPY_MODEL_f398df276cf5438eafb530aebf7817ad",
            "value": " 190/190 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "d2d6802b498343edaaff8216bf1289ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56b45fd0f16546d288873ef4734a0b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e0a62c6dfd94950aae036a34759243b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16a523ff43c64a448a053828e8fe2b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6ef3c0ebd634b129534d1425cab3f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc5ea2a635e3481ba3ad13dc05896051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f398df276cf5438eafb530aebf7817ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkopJH7W-LSJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3QV8xgK1at6",
        "outputId": "2517b366-0618-4509-b2b8-74bf655683c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiEXr9FMqUM5",
        "outputId": "662e6d1e-88b9-4d05-df7b-8060f854b7ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur8_hOc-guBn",
        "outputId": "18fc822f-ff34-4f54-abf5-f5c5a59218d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory structure created!\n"
          ]
        }
      ],
      "source": [
        "# Create the directory structure\n",
        "import os\n",
        "\n",
        "dirs = [\n",
        "    'Trust_me_Im_wrong',\n",
        "    'Trust_me_Im_wrong/semantic_uncertainty',\n",
        "    'Trust_me_Im_wrong/semantic_uncertainty/uncertainty',\n",
        "\n",
        "    'Trust_me_Im_wrong/semantic_uncertainty/uncertainty/models',\n",
        "    'Trust_me_Im_wrong/semantic_uncertainty/uncertainty/uncertainty_measures',\n",
        "\n",
        "]\n",
        "\n",
        "for dir_path in dirs:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "print(\"Directory structure created!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bHwpsdw-Q6L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NX5tp3s0ayI1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "dirs = [\n",
        "    'Trust_me_Im_wrong/analysis',\n",
        "    'Trust_me_Im_wrong//visualization',\n",
        "     'Trust_me_Im_wrong/reporting',\n",
        "     'Trust_me_Im_wrong/reports',\n",
        "     'Trust_me_Im_wrong/visualizations'\n",
        "]\n",
        "for dir_path in dirs:\n",
        "    os.makedirs(dir_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tj8gvn88-rCO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kff_s7yeNwNT",
        "outputId": "ad241791-c6d8-42e0-c9f0-2095e0b23226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created __init__.py in Trust_me_Im_wrong/analysis\n",
            "Created __init__.py in Trust_me_Im_wrong//visualization\n",
            "Created __init__.py in Trust_me_Im_wrong/reporting\n",
            "Created __init__.py in Trust_me_Im_wrong/reports\n",
            "Created __init__.py in Trust_me_Im_wrong/visualizations\n"
          ]
        }
      ],
      "source": [
        "# Create __init__.py in each directory to mark as package\n",
        "for dir_path in dirs:\n",
        "    init_path = os.path.join(dir_path, '__init__.py')\n",
        "    if not os.path.exists(init_path):\n",
        "        with open(init_path, 'w', encoding='utf-8') as f:\n",
        "            f.write('# Init file for package\\n')\n",
        "        print(f'Created __init__.py in {dir_path}')\n",
        "    else:\n",
        "        print(f'__init__.py already exists in {dir_path}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Trust_me_Im_wrong/semantic_uncertainty/uncertainty/models/base_model.py\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Text, Optional, Tuple\n",
        "\n",
        "# Full stop sequences for post-processing (all languages)\n",
        "FULL_STOP_SEQUENCES = [\n",
        "    '\\n',\n",
        "]\n",
        "\n",
        "# API-compatible stop sequences (max 4 for DeepSeek/OpenAI API)\n",
        "API_STOP_SEQUENCES = [\n",
        "    '\\n',       # Double newline - most common separator\n",
        "    '.',        # Period - ends sentences\n",
        "]\n",
        "\n",
        "# Keep original for backward compatibility\n",
        "STOP_SEQUENCES = FULL_STOP_SEQUENCES\n",
        "\n",
        "\n",
        "class BaseModel(ABC):\n",
        "    \"\"\"Base model class with enhanced stop sequence handling.\"\"\"\n",
        "\n",
        "    # Class variables\n",
        "    stop_sequences: List[Text] = FULL_STOP_SEQUENCES\n",
        "    api_stop_sequences: List[Text] = API_STOP_SEQUENCES\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize with both API and full stop sequences.\"\"\"\n",
        "        self.stop_sequences = FULL_STOP_SEQUENCES\n",
        "        self.api_stop_sequences = API_STOP_SEQUENCES\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self, input_data: str, temperature: float):\n",
        "        \"\"\"\n",
        "        Generate a response from the model given input_data and temperature.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_p_true(self, input_data: str):\n",
        "        \"\"\"\n",
        "        Compute probability that the answer to input_data is 'True'.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def post_process_with_stops(\n",
        "        text: str,\n",
        "        stop_sequences: Optional[List[str]] = None,\n",
        "        preserve_stop: bool = False\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Post-process text by truncating at the first occurrence of any stop sequence.\n",
        "\n",
        "        Args:\n",
        "            text: Input text to process\n",
        "            stop_sequences: List of stop sequences (uses FULL_STOP_SEQUENCES if None)\n",
        "            preserve_stop: If True, include the stop sequence in output\n",
        "\n",
        "        Returns:\n",
        "            Truncated text\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return text\n",
        "\n",
        "        if stop_sequences is None:\n",
        "            stop_sequences = FULL_STOP_SEQUENCES\n",
        "\n",
        "        # Find the earliest occurrence of any stop sequence\n",
        "        earliest_pos = len(text)\n",
        "        earliest_stop = None\n",
        "\n",
        "        for stop in stop_sequences:\n",
        "            pos = text.find(stop)\n",
        "            if pos != -1 and pos < earliest_pos:\n",
        "                earliest_pos = pos\n",
        "                earliest_stop = stop\n",
        "\n",
        "        # Truncate at the earliest stop sequence\n",
        "        if earliest_pos < len(text):\n",
        "            if preserve_stop and earliest_stop:\n",
        "                return text[:earliest_pos + len(earliest_stop)]\n",
        "            else:\n",
        "                return text[:earliest_pos]\n",
        "\n",
        "        return text\n",
        "\n",
        "    @staticmethod\n",
        "    def clean_for_comparison(text: str) -> str:\n",
        "        \"\"\"\n",
        "        Aggressively clean text for accurate comparison and hallucination detection.\n",
        "        Removes special characters that shouldn't be considered as tokens.\n",
        "\n",
        "        Args:\n",
        "            text: Text to clean\n",
        "\n",
        "        Returns:\n",
        "            Cleaned text\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove common articles and fillers\n",
        "        remove_words = ['the', 'a', 'an', 'is', 'are', 'was', 'were']\n",
        "        for word in remove_words:\n",
        "            text = text.replace(f\" {word} \", \" \")\n",
        "\n",
        "        # Remove all punctuation and special characters\n",
        "        special_chars = [\n",
        "             '!', '?', ';', ',', '.', ':', '\"', \"'\", \"-\", \"_\"\n",
        "        ]\n",
        "\n",
        "        for char in special_chars:\n",
        "            text = text.replace(char, ' ')\n",
        "\n",
        "        # Normalize whitespace\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def get_api_compatible_stops() -> List[str]:\n",
        "        \"\"\"\n",
        "        Get API-compatible stop sequences (max 4).\n",
        "\n",
        "        Returns:\n",
        "            List of up to 4 stop sequences for API calls\n",
        "        \"\"\"\n",
        "        return API_STOP_SEQUENCES[:4]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_all_stops() -> List[str]:\n",
        "        \"\"\"\n",
        "        Get all stop sequences for post-processing.\n",
        "\n",
        "        Returns:\n",
        "            Complete list of stop sequences\n",
        "        \"\"\"\n",
        "        return FULL_STOP_SEQUENCES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn28QNwAnAOk",
        "outputId": "47c48069-8d65-4237-9e85-32a41cafa622"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Trust_me_Im_wrong/semantic_uncertainty/uncertainty/models/base_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Trust_me_Im_wrong/calc_semantic_entropy_api.py\n",
        "\"\"\"\n",
        "Semantic Entropy Calculation for API Models (DeepSeek V3 - English) - CORRECTED\n",
        "Uses DeepSeek API with logprobs and sentence transformers for clustering.\n",
        "\n",
        "FIXES APPLIED:\n",
        "1. Softmax-based probability estimation (fixes logprob=0 issue)\n",
        "2. Corrected entropy calculations with proper clipping\n",
        "3. Sequence-based logprob extraction\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from transformers import AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Try to import google colab userdata, fallback to env vars\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    def get_secret(key):\n",
        "        return userdata.get(key)\n",
        "except ImportError:\n",
        "    import os\n",
        "    def get_secret(key):\n",
        "        return os.environ.get(key)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STOP SEQUENCES\n",
        "# ============================================================================\n",
        "FULL_STOP_SEQUENCES = ['\\n']\n",
        "API_STOP_SEQUENCES = ['\\n', '.']\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# HELPER: Post-process text with stop sequences\n",
        "# ============================================================================\n",
        "def post_process_with_stops(text, stop_sequences=None, preserve_stop=False):\n",
        "    \"\"\"Truncate text at the first occurrence of any stop sequence.\"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "    if stop_sequences is None:\n",
        "        stop_sequences = FULL_STOP_SEQUENCES\n",
        "\n",
        "    earliest_pos = len(text)\n",
        "    earliest_stop = None\n",
        "\n",
        "    for stop in stop_sequences:\n",
        "        pos = text.find(stop)\n",
        "        if pos != -1 and pos < earliest_pos:\n",
        "            earliest_pos = pos\n",
        "            earliest_stop = stop\n",
        "\n",
        "    if earliest_pos < len(text):\n",
        "        if preserve_stop and earliest_stop:\n",
        "            return text[:earliest_pos + len(earliest_stop)]\n",
        "        else:\n",
        "            return text[:earliest_pos]\n",
        "    return text\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CORRECTED: Softmax Normalizer for LogProbs\n",
        "# ============================================================================\n",
        "def softmax_normalize(logprobs):\n",
        "    \"\"\"\n",
        "    Apply softmax normalization to logprobs for numerical stability.\n",
        "\n",
        "    Args:\n",
        "        logprobs: List of log probabilities\n",
        "\n",
        "    Returns:\n",
        "        List of normalized probabilities that sum to ~1.0\n",
        "    \"\"\"\n",
        "    if not logprobs:\n",
        "        return []\n",
        "\n",
        "    # Convert to numpy for stability\n",
        "    lps = np.array(logprobs, dtype=np.float64)\n",
        "\n",
        "    # Clip extreme values\n",
        "    lps = np.clip(lps, -100, 0)\n",
        "\n",
        "    # Subtract max for numerical stability (prevents overflow)\n",
        "    max_lp = np.max(lps)\n",
        "    exp_scores = np.exp(lps - max_lp)\n",
        "\n",
        "    # Normalize\n",
        "    sum_exp = np.sum(exp_scores)\n",
        "    if sum_exp == 0:\n",
        "        return [1.0 / len(logprobs)] * len(logprobs)  # Uniform fallback\n",
        "\n",
        "    probs = exp_scores / sum_exp\n",
        "    return probs.tolist()\n",
        "\n",
        "\n",
        "def estimate_logprob_from_alternatives(top_logprobs, debug=False):\n",
        "    \"\"\"\n",
        "    Estimate meaningful logprob when API returns 0 for selected token.\n",
        "\n",
        "    Uses softmax over alternatives to get relative probability.\n",
        "\n",
        "    Args:\n",
        "        top_logprobs: List of top_logprobs objects from API\n",
        "        debug: Print debug info\n",
        "\n",
        "    Returns:\n",
        "        Estimated logprob (negative value)\n",
        "    \"\"\"\n",
        "    if not top_logprobs or len(top_logprobs) < 2:\n",
        "        return -1.0  # Default uncertainty\n",
        "\n",
        "    raw_lps = []\n",
        "    for alt in top_logprobs[:10]:\n",
        "        lp = getattr(alt, 'logprob', None)\n",
        "        if lp is not None:\n",
        "            raw_lps.append(lp)\n",
        "\n",
        "    if len(raw_lps) < 2:\n",
        "        return -1.0\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probs = softmax_normalize(raw_lps)\n",
        "\n",
        "    # First token's estimated probability\n",
        "    estimated_prob = probs[0] if probs else 0.5\n",
        "\n",
        "    # Convert back to logprob\n",
        "    estimated_logprob = np.log(estimated_prob + 1e-10)\n",
        "\n",
        "    if debug:\n",
        "        print(f\"  Estimated logprob: {estimated_logprob:.4f} (prob={estimated_prob:.4f})\")\n",
        "\n",
        "    return float(estimated_logprob)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Semantic Entropy Calculator\n",
        "# ============================================================================\n",
        "class SemanticEntropyAPI:\n",
        "    \"\"\"\n",
        "    Semantic entropy calculation with CORRECTED logprobs handling.\n",
        "\n",
        "    Key Fix: When DeepSeek returns logprob=0 for selected token,\n",
        "    we estimate using softmax over alternatives.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"deepseek-chat\", dataset_path=\"datasets/\",\n",
        "                 entailment_model=\"sentence_transformer\", max_new_tokens=10, debug=False):\n",
        "        \"\"\"\n",
        "        Initialize semantic entropy calculator for DeepSeek API.\n",
        "        \"\"\"\n",
        "        random.seed(0)\n",
        "        self.model_name = model_name\n",
        "        self.max_new_tokens = max_new_tokens\n",
        "        self.debug = debug\n",
        "\n",
        "        # 1. Initialize API client for DeepSeek\n",
        "        try:\n",
        "            api_key = get_secret('deepseek')\n",
        "            if not api_key:\n",
        "                raise ValueError(\"DeepSeek API key not found in secrets.\")\n",
        "\n",
        "            self.client = OpenAI(\n",
        "                api_key=api_key,\n",
        "                base_url=\"https://api.deepseek.com\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to initialize DeepSeek API client: {e}\")\n",
        "\n",
        "        # 2. Initialize Tokenizer\n",
        "        try:\n",
        "            hf_token = get_secret('hftoken')\n",
        "            if not hf_token:\n",
        "                print(\"Warning: 'hftoken' secret not found. Tokenizer load might fail if model is gated.\")\n",
        "\n",
        "            tokenizer_path = \"deepseek-ai/DeepSeek-V3\"\n",
        "            print(f\"Loading DeepSeek tokenizer from {tokenizer_path}...\")\n",
        "\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                tokenizer_path,\n",
        "                token=hf_token,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"CRITICAL: Failed to load DeepSeek tokenizer. Error: {e}\")\n",
        "\n",
        "        # 3. Initialize sentence transformer for semantic similarity\n",
        "        # KEEPING English model as requested\n",
        "        print(\"Loading English embedding model for semantic clustering...\")\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        # Clustering threshold\n",
        "        self.clustering_threshold = 0.5\n",
        "\n",
        "        # Setup stop sequences\n",
        "        self.api_stops = API_STOP_SEQUENCES[:4]\n",
        "        self.full_stops = FULL_STOP_SEQUENCES\n",
        "\n",
        "        print(f\"Initialized SemanticEntropyAPI with CORRECTED logprobs handling\")\n",
        "        print(f\"  Model: {model_name}\")\n",
        "        print(f\"  Clustering threshold: {self.clustering_threshold}\")\n",
        "\n",
        "    def generate_answers(self, prompt, answer, num_generations=11, temperature=1.0, compute_acc=False):\n",
        "        \"\"\"\n",
        "        Generate multiple answers for entropy calculation.\n",
        "\n",
        "        Args:\n",
        "            prompt: Input prompt\n",
        "            answer: Ground truth answer\n",
        "            num_generations: Number of generations (default 11)\n",
        "            temperature: Sampling temperature\n",
        "            compute_acc: Whether to compute accuracy\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with generations and metadata\n",
        "        \"\"\"\n",
        "        generations = {prompt: {\"question\": prompt}}\n",
        "        full_responses = []\n",
        "        all_generation_texts = []\n",
        "\n",
        "        system_message = \"Provide direct, brief answers without explanation.\"\n",
        "\n",
        "        print(f\"Generating {num_generations} responses...\")\n",
        "\n",
        "        for i in range(num_generations):\n",
        "            # First generation at low temperature for \"most likely\" answer\n",
        "            temp = 0.1 if i == 0 else temperature\n",
        "\n",
        "            response_data = self._get_api_response(prompt, temp, system_message)\n",
        "            all_generation_texts.append(response_data[\"text\"])\n",
        "\n",
        "            if i == 0:\n",
        "                most_likely_answer_dict = {\n",
        "                    \"response\": response_data[\"text\"],\n",
        "                    \"token_log_likelihoods\": response_data[\"token_logprobs\"],\n",
        "                    \"embedding\": None,\n",
        "                    \"accuracy\": self._check_accuracy(response_data[\"text\"], answer) if compute_acc else 0.0,\n",
        "                    \"total_logprob\": response_data[\"total_logprob\"]\n",
        "                }\n",
        "                generations[prompt][\"most_likely_answer\"] = most_likely_answer_dict\n",
        "            else:\n",
        "                full_responses.append((\n",
        "                    response_data[\"text\"],\n",
        "                    response_data[\"token_logprobs\"],\n",
        "                    None,\n",
        "                    self._check_accuracy(response_data[\"text\"], answer) if compute_acc else 0.0,\n",
        "                    response_data[\"total_logprob\"]\n",
        "                ))\n",
        "\n",
        "        generations[prompt][\"responses\"] = full_responses\n",
        "        generations[prompt][\"reference\"] = answer\n",
        "        generations[prompt][\"all_generation_texts\"] = all_generation_texts\n",
        "\n",
        "        print(f\"Generated texts: {all_generation_texts[:3]}...\")\n",
        "\n",
        "        return {\n",
        "            \"accuracies\": [most_likely_answer_dict[\"accuracy\"]] if generations[prompt].get(\"most_likely_answer\") else [],\n",
        "            \"generations\": generations,\n",
        "            \"question\": prompt,\n",
        "            \"reference\": answer,\n",
        "            \"all_generation_texts\": all_generation_texts\n",
        "        }\n",
        "\n",
        "    def _get_api_response(self, prompt, temperature, system_message=None):\n",
        "        \"\"\"\n",
        "        Get response from DeepSeek API with CORRECTED logprobs extraction.\n",
        "\n",
        "        Fix: When logprob=0 (broken), estimate using softmax over top_logprobs.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            messages = []\n",
        "            if system_message:\n",
        "                messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=messages,\n",
        "                temperature=temperature,\n",
        "                max_tokens=self.max_new_tokens,\n",
        "                logprobs=True,\n",
        "                top_logprobs=20,\n",
        "                stop=self.api_stops\n",
        "            )\n",
        "\n",
        "            choice = response.choices[0]\n",
        "            raw_text = choice.message.content or \"\"\n",
        "            processed_text = post_process_with_stops(raw_text, self.full_stops)\n",
        "\n",
        "            # CORRECTED: Extract logprobs with fallback estimation\n",
        "            total_logprob = 0.0\n",
        "            token_logprobs = []\n",
        "\n",
        "            logprobs_content = None\n",
        "            if hasattr(choice, 'logprobs') and choice.logprobs:\n",
        "                logprobs_content = getattr(choice.logprobs, 'content', None)\n",
        "\n",
        "            if logprobs_content:\n",
        "                for token_data in logprobs_content:\n",
        "                    logprob = getattr(token_data, 'logprob', None)\n",
        "\n",
        "                    # CRITICAL FIX: If logprob is 0 or None, estimate from alternatives\n",
        "                    if logprob is None or logprob >= -0.001:  # Effectively 0\n",
        "                        top_lps = getattr(token_data, 'top_logprobs', [])\n",
        "                        logprob = estimate_logprob_from_alternatives(top_lps, self.debug)\n",
        "\n",
        "                    token_logprobs.append(logprob)\n",
        "                    total_logprob += logprob\n",
        "\n",
        "                    if self.debug:\n",
        "                        token_text = getattr(token_data, 'token', '?')\n",
        "                        print(f\"  Token: '{token_text}', logprob: {logprob:.4f}\")\n",
        "\n",
        "            return {\n",
        "                \"text\": processed_text,\n",
        "                \"raw_text\": raw_text,\n",
        "                \"token_logprobs\": token_logprobs,\n",
        "                \"total_logprob\": total_logprob\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"API error: {e}\")\n",
        "            return {\n",
        "                \"text\": \"\",\n",
        "                \"raw_text\": \"\",\n",
        "                \"token_logprobs\": [],\n",
        "                \"total_logprob\": -10.0\n",
        "            }\n",
        "\n",
        "    def _check_accuracy(self, generated, target):\n",
        "        \"\"\"Check if generated text matches target (basic check).\"\"\"\n",
        "        if not generated or not target:\n",
        "            return 0.0\n",
        "\n",
        "        gen_clean = generated.lower().strip()\n",
        "        target_clean = target.lower().strip()\n",
        "\n",
        "        if target_clean in gen_clean or gen_clean in target_clean:\n",
        "            return 1.0\n",
        "        return 0.0\n",
        "\n",
        "    def compute_uncertainty_measures(self, model_generations, compute_predictive_entropy=True, strict_entailment=False):\n",
        "        \"\"\"\n",
        "        Compute semantic entropy and other uncertainty measures.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (avg_entropies dict, result_dict with debug info)\n",
        "        \"\"\"\n",
        "        result_dict = {\"semantic_ids\": [], \"debug_info\": {}}\n",
        "        entropies = defaultdict(list)\n",
        "\n",
        "        for tid in model_generations:\n",
        "            example = model_generations[tid]\n",
        "            full_responses = example.get(\"responses\", [])\n",
        "\n",
        "            # Include the most likely answer\n",
        "            if \"most_likely_answer\" in example:\n",
        "                most_likely = example[\"most_likely_answer\"]\n",
        "                tll = most_likely.get(\"token_log_likelihoods\", [])\n",
        "                full_responses.insert(0, (\n",
        "                    most_likely[\"response\"],\n",
        "                    tll,\n",
        "                    None,\n",
        "                    most_likely.get(\"accuracy\", 0),\n",
        "                    most_likely.get(\"total_logprob\", sum(tll) if tll else -10)\n",
        "                ))\n",
        "\n",
        "            if not full_responses:\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nProcessing {len(full_responses)} total generations\")\n",
        "\n",
        "            raw_responses = [r[0] for r in full_responses]\n",
        "            responses = [post_process_with_stops(r, self.full_stops) for r in raw_responses]\n",
        "\n",
        "            if compute_predictive_entropy:\n",
        "                # Get total log likelihoods\n",
        "                total_log_liks = []\n",
        "                for r in full_responses:\n",
        "                    if len(r) >= 5 and r[4] is not None:\n",
        "                        total_log_liks.append(r[4])\n",
        "                    elif r[1]:\n",
        "                        total_log_liks.append(sum(r[1]))\n",
        "                    else:\n",
        "                        total_log_liks.append(-10)\n",
        "\n",
        "                print(f\"Total log likelihoods: {[f'{ll:.2f}' for ll in total_log_liks[:3]]}...\")\n",
        "\n",
        "                # Compute semantic IDs using clustering\n",
        "                semantic_ids = self._get_semantic_ids_clustering(responses)\n",
        "                result_dict[\"semantic_ids\"].append(semantic_ids)\n",
        "\n",
        "                print(f\"Semantic IDs: {semantic_ids}\")\n",
        "                unique_clusters = len(set(sid for sid in semantic_ids if sid >= 0))\n",
        "                print(f\"Number of semantic clusters: {unique_clusters}\")\n",
        "\n",
        "                result_dict[\"debug_info\"][\"num_generations\"] = len(full_responses)\n",
        "                result_dict[\"debug_info\"][\"num_clusters\"] = unique_clusters\n",
        "                result_dict[\"debug_info\"][\"responses_sample\"] = responses[:3]\n",
        "\n",
        "                # Cluster assignment entropy (CLIPPED)\n",
        "                cluster_entropy = self._cluster_assignment_entropy(semantic_ids)\n",
        "                cluster_entropy = max(0.0, cluster_entropy)  # FIX: Clip to non-negative\n",
        "                entropies[\"cluster_assignment_entropy\"].append(cluster_entropy)\n",
        "                print(f\"Cluster assignment entropy: {cluster_entropy:.4f}\")\n",
        "\n",
        "                # Regular entropy\n",
        "                regular_entropy = self._predictive_entropy(total_log_liks)\n",
        "                regular_entropy = max(0.0, regular_entropy)  # FIX: Clip\n",
        "                entropies[\"regular_entropy\"].append(regular_entropy)\n",
        "                print(f\"Regular entropy: {regular_entropy:.4f}\")\n",
        "\n",
        "                # Semantic entropy\n",
        "                log_lik_per_cluster = self._logsumexp_by_id(semantic_ids, total_log_liks)\n",
        "                semantic_entropy = self._semantic_entropy(log_lik_per_cluster)\n",
        "                semantic_entropy = max(0.0, semantic_entropy)  # FIX: Clip\n",
        "                entropies[\"semantic_entropy\"].append(semantic_entropy)\n",
        "                print(f\"Semantic entropy: {semantic_entropy:.4f}\")\n",
        "\n",
        "        avg_entropies = {k: float(np.mean(v)) if v else 0.0 for k, v in entropies.items()}\n",
        "        return avg_entropies, result_dict\n",
        "\n",
        "    def _get_semantic_ids_clustering(self, responses):\n",
        "        \"\"\"Cluster responses using sentence embeddings.\"\"\"\n",
        "        if not responses or len(responses) <= 1:\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        valid_responses = [r for r in responses if r and r.strip()]\n",
        "        if not valid_responses:\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        print(f\"Clustering {len(valid_responses)} responses\")\n",
        "\n",
        "        try:\n",
        "            embeddings = self.embedding_model.encode(valid_responses)\n",
        "        except Exception as e:\n",
        "            print(f\"Embedding error: {e}\")\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        if len(valid_responses) == 1:\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        clustering = AgglomerativeClustering(\n",
        "            n_clusters=None,\n",
        "            distance_threshold=self.clustering_threshold,\n",
        "            linkage='average'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            semantic_ids = clustering.fit_predict(embeddings)\n",
        "\n",
        "            # Map back to full response list\n",
        "            full_ids = []\n",
        "            valid_idx = 0\n",
        "            for r in responses:\n",
        "                if r and r.strip():\n",
        "                    full_ids.append(int(semantic_ids[valid_idx]))\n",
        "                    valid_idx += 1\n",
        "                else:\n",
        "                    full_ids.append(-1)\n",
        "            return full_ids\n",
        "        except Exception as e:\n",
        "            print(f\"Clustering error: {e}\")\n",
        "            return [0] * len(responses)\n",
        "\n",
        "    def _cluster_assignment_entropy(self, semantic_ids):\n",
        "        \"\"\"Calculate entropy of cluster assignments.\"\"\"\n",
        "        if not semantic_ids:\n",
        "            return 0.0\n",
        "\n",
        "        valid_ids = [sid for sid in semantic_ids if sid >= 0]\n",
        "        if not valid_ids:\n",
        "            return 0.0\n",
        "\n",
        "        counts = defaultdict(int)\n",
        "        for sid in valid_ids:\n",
        "            counts[sid] += 1\n",
        "\n",
        "        total = len(valid_ids)\n",
        "        entropy = 0.0\n",
        "        for count in counts.values():\n",
        "            p = count / total\n",
        "            if p > 0:\n",
        "                entropy -= p * np.log(p)\n",
        "\n",
        "        return float(entropy)\n",
        "\n",
        "    def _predictive_entropy(self, log_likelihoods):\n",
        "        \"\"\"Calculate predictive entropy from log likelihoods.\"\"\"\n",
        "        if not log_likelihoods:\n",
        "            return 0.0\n",
        "\n",
        "        # Normalize to get probabilities via softmax\n",
        "        log_liks = np.array(log_likelihoods, dtype=np.float64)\n",
        "        max_ll = np.max(log_liks)\n",
        "\n",
        "        exp_liks = np.exp(log_liks - max_ll)\n",
        "        probs = exp_liks / np.sum(exp_liks)\n",
        "\n",
        "        # Calculate entropy\n",
        "        entropy = 0.0\n",
        "        for p in probs:\n",
        "            if p > 1e-10:\n",
        "                entropy -= p * np.log(p)\n",
        "\n",
        "        return float(entropy)\n",
        "\n",
        "    def _logsumexp_by_id(self, semantic_ids, log_likelihoods):\n",
        "        \"\"\"Aggregate log likelihoods by semantic cluster using logsumexp.\"\"\"\n",
        "        if len(semantic_ids) != len(log_likelihoods):\n",
        "            return log_likelihoods\n",
        "\n",
        "        clusters = defaultdict(list)\n",
        "        for sid, ll in zip(semantic_ids, log_likelihoods):\n",
        "            if sid >= 0:\n",
        "                clusters[sid].append(ll)\n",
        "\n",
        "        result = []\n",
        "        for sid in sorted(clusters.keys()):\n",
        "            lls = clusters[sid]\n",
        "            # logsumexp for numerical stability\n",
        "            max_ll = max(lls)\n",
        "            aggregated = max_ll + np.log(sum(np.exp(ll - max_ll) for ll in lls))\n",
        "            result.append(aggregated)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _semantic_entropy(self, log_likelihoods):\n",
        "        \"\"\"Calculate semantic entropy from aggregated log likelihoods.\"\"\"\n",
        "        return self._predictive_entropy(log_likelihoods)\n",
        "\n",
        "    def calc_semantic_entropy_per_example(self, prompt, answer, temp=1.0, num_generations=11):\n",
        "        \"\"\"\n",
        "        Calculate semantic entropy for a single example.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (entropy_dict, generation_details)\n",
        "        \"\"\"\n",
        "        print(f\"\\nCalculating semantic entropy with {num_generations} generations (temp={temp})...\")\n",
        "\n",
        "        results = self.generate_answers(\n",
        "            prompt=prompt,\n",
        "            answer=answer,\n",
        "            num_generations=num_generations,\n",
        "            temperature=temp,\n",
        "            compute_acc=True\n",
        "        )\n",
        "\n",
        "        avg_entropies, extra_info = self.compute_uncertainty_measures(\n",
        "            results[\"generations\"],\n",
        "            compute_predictive_entropy=True,\n",
        "            strict_entailment=False\n",
        "        )\n",
        "\n",
        "        # Add all generation texts to output\n",
        "        avg_entropies[\"all_generations\"] = results.get(\"all_generation_texts\", [])\n",
        "        avg_entropies[\"debug_info\"] = extra_info.get(\"debug_info\", {})\n",
        "\n",
        "        return avg_entropies, results[\"generations\"]\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Standalone Usage\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 80)\n",
        "    print(\"Semantic Entropy Calculator - CORRECTED VERSION\")\n",
        "    print(\"Fixes: logprob=0 estimation, entropy clipping\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Example usage:\n",
        "    # calculator = SemanticEntropyAPI(model_name=\"deepseek-chat\", debug=True)\n",
        "    # result, details = calculator.calc_semantic_entropy_per_example(\n",
        "    #     prompt=\"What is the capital of France?\",\n",
        "    #     answer=\"Paris\",\n",
        "    #     num_generations=11\n",
        "    # )\n",
        "    # print(f\"Semantic entropy: {result['semantic_entropy']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-uNtgP6EIbo",
        "outputId": "3673bbce-55bc-4611-94f3-6fa38ada75d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Trust_me_Im_wrong/calc_semantic_entropy_api.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Trust_me_Im_wrong/uncertainty_calculation_api.py\n",
        "\"\"\"\n",
        "Corrected Uncertainty Calculation API for DeepSeek (English) - V2\n",
        "================================================================================\n",
        "\n",
        "FIXES APPLIED:\n",
        "1. LogProbsExtractor: Softmax-based probability estimation (fixes logprob=0)\n",
        "2. EnglishTextMatcher: Fuzzy matching with number normalization\n",
        "3. Entropy clipping to non-negative values\n",
        "4. Proper semantic equivalence handling\n",
        "\n",
        "Key Fix: DeepSeek API returns logprob=0 for selected token, making direct\n",
        "probability extraction useless (exp(0)=1.0 always). This version uses softmax\n",
        "normalization over all available top_logprobs to estimate meaningful probabilities.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "from collections import defaultdict\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Try to import google colab userdata, fallback to env vars\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    def get_secret(key):\n",
        "        return userdata.get(key)\n",
        "except ImportError:\n",
        "    def get_secret(key):\n",
        "        return os.environ.get(key)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STOP SEQUENCES\n",
        "# ============================================================================\n",
        "FULL_STOP_SEQUENCES = ['\\n']\n",
        "API_STOP_SEQUENCES = ['\\n', '.']\n",
        "\n",
        "# Tokens to exclude from alternatives\n",
        "EXCLUDED_TOKENS = {\n",
        "    '', ' ', '\\n', '\\t', '\\r', '\\\\n', '\\\\t', '\\\\r',\n",
        "    '<|endoftext|>', '<|im_end|>', '<|im_start|>',\n",
        "    '<eos>', '<pad>', '<unk>', '<s>', '</s>',\n",
        "    '▁', '##', '@@'\n",
        "}\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# HELPER: Post-process text with stop sequences\n",
        "# ============================================================================\n",
        "def post_process_with_stops(text, stop_sequences=None, preserve_stop=False):\n",
        "    \"\"\"Truncate text at the first occurrence of any stop sequence.\"\"\"\n",
        "    if not text:\n",
        "        return text\n",
        "    if stop_sequences is None:\n",
        "        stop_sequences = FULL_STOP_SEQUENCES\n",
        "\n",
        "    earliest_pos = len(text)\n",
        "    earliest_stop = None\n",
        "\n",
        "    for stop in stop_sequences:\n",
        "        pos = text.find(stop)\n",
        "        if pos != -1 and pos < earliest_pos:\n",
        "            earliest_pos = pos\n",
        "            earliest_stop = stop\n",
        "\n",
        "    if earliest_pos < len(text):\n",
        "        if preserve_stop and earliest_stop:\n",
        "            return text[:earliest_pos + len(earliest_stop)]\n",
        "        else:\n",
        "            return text[:earliest_pos]\n",
        "    return text\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CORRECTED: LogProbs Extractor with Softmax Estimation\n",
        "# ============================================================================\n",
        "class LogProbsExtractor:\n",
        "    \"\"\"\n",
        "    Extracts and estimates probabilities from DeepSeek API responses.\n",
        "\n",
        "    PROBLEM: DeepSeek API returns logprob=0 for the selected token, which\n",
        "    gives exp(0)=1.0, making probability extraction useless.\n",
        "\n",
        "    SOLUTION: Use softmax normalization over all available top_logprobs\n",
        "    to estimate relative probabilities among the top candidates.\n",
        "\n",
        "    Example:\n",
        "        Raw logprobs: [0.0, -2.1, -4.5, -3.8]  (first is broken)\n",
        "        After softmax: [0.857, 0.105, 0.009, 0.019]  (meaningful!)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, debug=False):\n",
        "        self.debug = debug\n",
        "\n",
        "    def _is_valid_token(self, raw_token):\n",
        "        \"\"\"\n",
        "        Check if token should be included in probability calculation.\n",
        "\n",
        "        Filters out:\n",
        "        - Empty tokens\n",
        "        - Special tokens (various Unicode formats)\n",
        "        - Pure punctuation\n",
        "        - Whitespace-only tokens\n",
        "        - Sentence piece markers\n",
        "        \"\"\"\n",
        "        if not raw_token:\n",
        "            return False\n",
        "\n",
        "        token = raw_token.strip()\n",
        "\n",
        "        if not token:\n",
        "            return False\n",
        "\n",
        "        # Skip excluded tokens\n",
        "        if raw_token in EXCLUDED_TOKENS or token in EXCLUDED_TOKENS:\n",
        "            return False\n",
        "\n",
        "        # ============================================================\n",
        "        # ROBUST SPECIAL TOKEN DETECTION\n",
        "        # DeepSeek uses various Unicode characters for special tokens\n",
        "        # ============================================================\n",
        "\n",
        "        # Standard ASCII special tokens: <|...|>\n",
        "        if raw_token.startswith(\"<|\") and raw_token.endswith(\"|>\"):\n",
        "            return False\n",
        "\n",
        "        # Unicode fullwidth special tokens: <｜...｜>\n",
        "        # ｜ is U+FF5C (fullwidth vertical line)\n",
        "        if raw_token.startswith(\"<｜\") or raw_token.endswith(\"｜>\"):\n",
        "            return False\n",
        "\n",
        "        # Any token containing special markers\n",
        "        special_markers = [\n",
        "            \"▁\",           # Sentence piece marker (U+2581)\n",
        "            \"｜\",           # Fullwidth vertical line (U+FF5C)\n",
        "            \"<|\",          # ASCII special token start\n",
        "            \"|>\",          # ASCII special token end\n",
        "            \"end_of\",      # Common special token pattern\n",
        "            \"end▁of\",      # With sentence piece\n",
        "            \"begin_of\",    # Common special token pattern\n",
        "            \"begin▁of\",    # With sentence piece\n",
        "            \"sentence\",    # Part of special tokens\n",
        "            \"padding\",     # Padding token\n",
        "            \"endoftext\",   # End of text\n",
        "            \"im_start\",    # Chat template\n",
        "            \"im_end\",      # Chat template\n",
        "            \"<eos>\",       # End of sequence\n",
        "            \"<bos>\",       # Begin of sequence\n",
        "            \"<pad>\",       # Padding\n",
        "            \"<unk>\",       # Unknown\n",
        "            \"<s>\",         # Start\n",
        "            \"</s>\",        # End\n",
        "        ]\n",
        "\n",
        "        token_lower = raw_token.lower()\n",
        "        for marker in special_markers:\n",
        "            if marker.lower() in token_lower:\n",
        "                return False\n",
        "\n",
        "        # Skip tokens that are mostly special characters\n",
        "        alnum_count = sum(1 for c in token if c.isalnum())\n",
        "        if len(token) > 0 and alnum_count / len(token) < 0.5:\n",
        "            return False\n",
        "\n",
        "        # Skip pure punctuation (but allow mixed like \"don't\")\n",
        "        if all(char in string.punctuation for char in token):\n",
        "            return False\n",
        "\n",
        "        # Skip very short tokens that are just symbols\n",
        "        if len(token) == 1 and not token.isalpha():\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _softmax_normalize(self, logprobs):\n",
        "        \"\"\"\n",
        "        Apply softmax normalization to logprobs for numerical stability.\n",
        "\n",
        "        Args:\n",
        "            logprobs: List of log probabilities\n",
        "\n",
        "        Returns:\n",
        "            List of normalized probabilities that sum to ~1.0\n",
        "        \"\"\"\n",
        "        if not logprobs:\n",
        "            return []\n",
        "\n",
        "        # Convert to numpy for stability\n",
        "        lps = np.array(logprobs, dtype=np.float64)\n",
        "\n",
        "        # Clip extreme values to prevent numerical issues\n",
        "        lps = np.clip(lps, -100, 0)\n",
        "\n",
        "        # Subtract max for numerical stability (prevents overflow)\n",
        "        max_lp = np.max(lps)\n",
        "        exp_scores = np.exp(lps - max_lp)\n",
        "\n",
        "        # Normalize\n",
        "        sum_exp = np.sum(exp_scores)\n",
        "        if sum_exp == 0:\n",
        "            return [1.0 / len(logprobs)] * len(logprobs)  # Uniform fallback\n",
        "\n",
        "        probs = exp_scores / sum_exp\n",
        "        return probs.tolist()\n",
        "\n",
        "    def extract_all_probabilities(self, logprobs_content, max_alternatives=5, answer_text=None):\n",
        "        \"\"\"\n",
        "        Extract first token probability and alternatives using softmax.\n",
        "\n",
        "        Args:\n",
        "            logprobs_content: The logprobs.content from API response\n",
        "            max_alternatives: Maximum number of alternatives to return\n",
        "            answer_text: The actual generated answer (for sequence calculation)\n",
        "\n",
        "        Returns:\n",
        "            dict with probabilities and metadata\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            \"first_token_probability\": 0.5,\n",
        "            \"first_token_logprob\": None,\n",
        "            \"probability_source\": \"unknown\",\n",
        "            \"top_word_alternatives\": [],\n",
        "            \"prob_diff_top2\": 0.0,\n",
        "            \"debug_info\": {\n",
        "                \"raw_logprobs\": [],\n",
        "                \"all_tokens\": [],\n",
        "                \"all_raw_tokens\": [],\n",
        "                \"filtered_count\": 0,\n",
        "                \"softmax_applied\": False,\n",
        "                \"sequence_logprobs\": [],\n",
        "                \"sequence_tokens\": []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Early exit if no data\n",
        "        if not logprobs_content or len(logprobs_content) == 0:\n",
        "            result[\"probability_source\"] = \"no_data\"\n",
        "            if self.debug:\n",
        "                print(\"WARNING: No logprobs content available\")\n",
        "            return result\n",
        "\n",
        "        # ============================================================\n",
        "        # SEQUENCE-BASED PROBABILITY CALCULATION\n",
        "        # ============================================================\n",
        "        if answer_text and len(logprobs_content) >= 1:\n",
        "            seq_result = self._calculate_sequence_probability(\n",
        "                logprobs_content, answer_text, max_alternatives\n",
        "            )\n",
        "            if seq_result is not None:\n",
        "                return seq_result\n",
        "\n",
        "        # Fallback to first token method\n",
        "        return self._extract_first_token_probabilities(logprobs_content, max_alternatives)\n",
        "\n",
        "    def _calculate_sequence_probability(self, logprobs_content, answer_text, max_alternatives=5):\n",
        "        \"\"\"\n",
        "        Calculate probability based on FULL token sequence.\n",
        "\n",
        "        Since classification happens FIRST, the first token is ALWAYS part of\n",
        "        the answer. We calculate probability even if logprob=0 (broken).\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            \"first_token_probability\": 0.5,\n",
        "            \"first_token_logprob\": None,\n",
        "            \"probability_source\": \"unknown\",\n",
        "            \"top_word_alternatives\": [],\n",
        "            \"prob_diff_top2\": 0.0,\n",
        "            \"debug_info\": {\n",
        "                \"sequence_tokens\": [],\n",
        "                \"sequence_logprobs\": [],\n",
        "                \"valid_logprobs\": [],\n",
        "                \"avg_logprob\": None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if not logprobs_content or len(logprobs_content) == 0:\n",
        "            return None  # Use fallback\n",
        "\n",
        "        first_token_data = logprobs_content[0]\n",
        "        first_token = getattr(first_token_data, 'token', '')\n",
        "\n",
        "        if self.debug:\n",
        "            print(f\"\\nDEBUG SEQUENCE: Answer='{answer_text}', First token='{first_token}'\")\n",
        "\n",
        "        # ============================================================\n",
        "        # COLLECT ALL TOKEN LOGPROBS IN THE SEQUENCE\n",
        "        # ============================================================\n",
        "        sequence_tokens = []\n",
        "        sequence_logprobs = []\n",
        "\n",
        "        for i, token_data in enumerate(logprobs_content):\n",
        "            token = getattr(token_data, 'token', '')\n",
        "            logprob = getattr(token_data, 'logprob', None)\n",
        "\n",
        "            sequence_tokens.append(token)\n",
        "            sequence_logprobs.append(logprob if logprob is not None else 0.0)\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"  Token {i+1}: '{token}' → logprob={logprob}\")\n",
        "\n",
        "        result[\"debug_info\"][\"sequence_tokens\"] = sequence_tokens\n",
        "        result[\"debug_info\"][\"sequence_logprobs\"] = sequence_logprobs\n",
        "\n",
        "        # ============================================================\n",
        "        # GET ALTERNATIVES FROM FIRST TOKEN'S TOP_LOGPROBS\n",
        "        # ============================================================\n",
        "        top_logprobs = getattr(first_token_data, 'top_logprobs', None) or []\n",
        "\n",
        "        all_alt_logprobs = []\n",
        "        all_alt_tokens = []\n",
        "\n",
        "        for alt in top_logprobs:\n",
        "            alt_token = getattr(alt, 'token', '')\n",
        "            alt_logprob = getattr(alt, 'logprob', None)\n",
        "\n",
        "            if alt_logprob is None:\n",
        "                continue\n",
        "\n",
        "            all_alt_tokens.append(alt_token.strip())\n",
        "            all_alt_logprobs.append(alt_logprob)\n",
        "\n",
        "        if self.debug:\n",
        "            print(f\"DEBUG: All alternatives from API: {list(zip(all_alt_tokens[:5], all_alt_logprobs[:5]))}\")\n",
        "\n",
        "        # ============================================================\n",
        "        # CALCULATE FIRST TOKEN PROBABILITY USING SOFTMAX\n",
        "        # ============================================================\n",
        "        if len(all_alt_logprobs) >= 2:\n",
        "            # Apply softmax to get probabilities\n",
        "            all_lps = np.array(all_alt_logprobs, dtype=np.float64)\n",
        "            all_lps = np.clip(all_lps, -100, 0)\n",
        "\n",
        "            max_lp = np.max(all_lps)\n",
        "            exp_scores = np.exp(all_lps - max_lp)\n",
        "            probs = exp_scores / np.sum(exp_scores)\n",
        "\n",
        "            first_token_prob = float(probs[0])\n",
        "            first_token_logprob = float(all_alt_logprobs[0])\n",
        "\n",
        "            result[\"first_token_probability\"] = first_token_prob\n",
        "            result[\"first_token_logprob\"] = first_token_logprob\n",
        "            result[\"probability_source\"] = \"softmax_from_alternatives\"\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"DEBUG: Softmax probs: {[round(p, 4) for p in probs[:5]]}\")\n",
        "                print(f\"DEBUG: First token prob (softmax): {first_token_prob:.4f}\")\n",
        "\n",
        "            # ============================================================\n",
        "            # BUILD ALTERNATIVES LIST WITH SOFTMAX PROBS\n",
        "            # ============================================================\n",
        "            alternatives = []\n",
        "            seen_tokens = set()\n",
        "\n",
        "            for i, (token, prob) in enumerate(zip(all_alt_tokens, probs)):\n",
        "                if not token or not self._is_valid_token(token):\n",
        "                    continue\n",
        "\n",
        "                if token.lower() in seen_tokens:\n",
        "                    continue\n",
        "\n",
        "                seen_tokens.add(token.lower())\n",
        "                alternatives.append({\n",
        "                    \"token\": token,\n",
        "                    \"prob\": float(prob),\n",
        "                    \"logprob\": float(all_alt_logprobs[i])\n",
        "                })\n",
        "\n",
        "                if len(alternatives) >= max_alternatives:\n",
        "                    break\n",
        "\n",
        "            result[\"top_word_alternatives\"] = alternatives\n",
        "\n",
        "            # ============================================================\n",
        "            # CALCULATE PROB_DIFF\n",
        "            # ============================================================\n",
        "            if len(alternatives) >= 2:\n",
        "                result[\"prob_diff_top2\"] = float(\n",
        "                    alternatives[0][\"prob\"] - alternatives[1][\"prob\"]\n",
        "                )\n",
        "            elif len(alternatives) == 1:\n",
        "                result[\"prob_diff_top2\"] = float(alternatives[0][\"prob\"])\n",
        "\n",
        "            if self.debug:\n",
        "                if len(alternatives) >= 2:\n",
        "                    print(f\"DEBUG: prob_diff = {alternatives[0]['prob']:.4f} - {alternatives[1]['prob']:.4f} = {result['prob_diff_top2']:.4f}\")\n",
        "                print(f\"DEBUG: probability_source: {result['probability_source']}\")\n",
        "\n",
        "        else:\n",
        "            # Not enough alternatives - use sequence average as fallback\n",
        "            avg_logprob = sum(sequence_logprobs) / len(sequence_logprobs) if sequence_logprobs else 0.0\n",
        "            result[\"first_token_probability\"] = float(np.exp(np.clip(avg_logprob, -100, 0)))\n",
        "            result[\"first_token_logprob\"] = avg_logprob\n",
        "            result[\"probability_source\"] = \"sequence_average_fallback\"\n",
        "            result[\"debug_info\"][\"avg_logprob\"] = avg_logprob\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"DEBUG: Fallback to sequence average: {avg_logprob:.4f}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _extract_first_token_probabilities(self, logprobs_content, max_alternatives=5):\n",
        "        \"\"\"\n",
        "        Extract first token probability using softmax (fallback method).\n",
        "        \"\"\"\n",
        "        result = {\n",
        "            \"first_token_probability\": 0.5,\n",
        "            \"first_token_logprob\": None,\n",
        "            \"probability_source\": \"unknown\",\n",
        "            \"top_word_alternatives\": [],\n",
        "            \"prob_diff_top2\": 0.0,\n",
        "            \"debug_info\": {\n",
        "                \"raw_logprobs\": [],\n",
        "                \"all_tokens\": [],\n",
        "                \"filtered_count\": 0,\n",
        "                \"softmax_applied\": False\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if not logprobs_content or len(logprobs_content) == 0:\n",
        "            result[\"probability_source\"] = \"no_data\"\n",
        "            return result\n",
        "\n",
        "        first_token_data = logprobs_content[0]\n",
        "        top_logprobs = getattr(first_token_data, 'top_logprobs', None) or []\n",
        "\n",
        "        if not top_logprobs or len(top_logprobs) < 2:\n",
        "            result[\"probability_source\"] = \"insufficient_alternatives\"\n",
        "            return result\n",
        "\n",
        "        # Collect valid entries\n",
        "        valid_entries = []\n",
        "        for alt in top_logprobs:\n",
        "            raw_token = getattr(alt, 'token', '')\n",
        "            logprob = getattr(alt, 'logprob', None)\n",
        "\n",
        "            if not self._is_valid_token(raw_token) or logprob is None:\n",
        "                continue\n",
        "\n",
        "            token = raw_token.strip()\n",
        "            is_complete = len(token) >= 4 or (len(token) > 0 and token[0].isupper())\n",
        "\n",
        "            valid_entries.append({\n",
        "                \"token\": token,\n",
        "                \"logprob\": logprob,\n",
        "                \"is_complete\": is_complete\n",
        "            })\n",
        "\n",
        "        if len(valid_entries) < 1:\n",
        "            result[\"probability_source\"] = \"no_valid_alternatives\"\n",
        "            return result\n",
        "\n",
        "        # Apply softmax\n",
        "        all_logprobs = [e[\"logprob\"] for e in valid_entries]\n",
        "        softmax_probs = self._softmax_normalize(all_logprobs)\n",
        "        result[\"debug_info\"][\"softmax_applied\"] = True\n",
        "\n",
        "        for i, entry in enumerate(valid_entries):\n",
        "            entry[\"prob\"] = softmax_probs[i]\n",
        "\n",
        "        valid_entries.sort(key=lambda x: (x[\"is_complete\"], x[\"prob\"]), reverse=True)\n",
        "\n",
        "        first_entry = valid_entries[0]\n",
        "        result[\"first_token_probability\"] = float(first_entry[\"prob\"])\n",
        "        result[\"first_token_logprob\"] = float(first_entry[\"logprob\"])\n",
        "        result[\"probability_source\"] = \"softmax_estimated\"\n",
        "\n",
        "        # Build alternatives\n",
        "        seen_tokens = set()\n",
        "        alternatives = []\n",
        "        for entry in valid_entries:\n",
        "            if entry[\"token\"] not in seen_tokens:\n",
        "                seen_tokens.add(entry[\"token\"])\n",
        "                alternatives.append({\n",
        "                    \"token\": entry[\"token\"],\n",
        "                    \"prob\": float(entry[\"prob\"]),\n",
        "                    \"logprob\": float(entry[\"logprob\"])\n",
        "                })\n",
        "                if len(alternatives) >= max_alternatives:\n",
        "                    break\n",
        "\n",
        "        result[\"top_word_alternatives\"] = alternatives\n",
        "\n",
        "        if len(alternatives) >= 2:\n",
        "            result[\"prob_diff_top2\"] = float(alternatives[0][\"prob\"] - alternatives[1][\"prob\"])\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# English Text Matcher (Fuzzy Matching with Number Normalization)\n",
        "# ============================================================================\n",
        "class EnglishTextMatcher:\n",
        "    \"\"\"\n",
        "    English-aware text matching for answer comparison.\n",
        "\n",
        "    Features:\n",
        "    - Number normalization (\"4\" ↔ \"four\")\n",
        "    - Fuzzy string matching\n",
        "    - Token overlap scoring\n",
        "    - Semantic equivalence pairs\n",
        "    \"\"\"\n",
        "\n",
        "    ENGLISH_STOP_WORDS = {\n",
        "        'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',\n",
        "        'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
        "        'would', 'could', 'should', 'may', 'might', 'must', 'shall',\n",
        "        'can', 'of', 'in', 'to', 'for', 'with', 'on', 'at', 'by',\n",
        "        'from', 'as', 'it', 'its', 'this', 'that', 'these', 'those',\n",
        "        'and', 'or', 'but', 'if', 'then', 'so', 'because', 'although'\n",
        "    }\n",
        "\n",
        "    # Number mappings (digit to word)\n",
        "    NUMBER_TO_WORD = {\n",
        "        '0': 'zero', '1': 'one', '2': 'two', '3': 'three', '4': 'four',\n",
        "        '5': 'five', '6': 'six', '7': 'seven', '8': 'eight', '9': 'nine',\n",
        "        '10': 'ten', '11': 'eleven', '12': 'twelve', '13': 'thirteen',\n",
        "        '14': 'fourteen', '15': 'fifteen', '16': 'sixteen', '17': 'seventeen',\n",
        "        '18': 'eighteen', '19': 'nineteen', '20': 'twenty',\n",
        "        '30': 'thirty', '40': 'forty', '50': 'fifty', '60': 'sixty',\n",
        "        '70': 'seventy', '80': 'eighty', '90': 'ninety', '100': 'hundred',\n",
        "        '1000': 'thousand', '1st': 'first', '2nd': 'second', '3rd': 'third',\n",
        "        '4th': 'fourth', '5th': 'fifth', '6th': 'sixth', '7th': 'seventh',\n",
        "        '8th': 'eighth', '9th': 'ninth', '10th': 'tenth'\n",
        "    }\n",
        "\n",
        "    # Word forms set (for checking if already a word)\n",
        "    WORD_FORMS = {\n",
        "        'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine',\n",
        "        'ten', 'eleven', 'twelve', 'thirteen', 'fourteen', 'fifteen', 'sixteen',\n",
        "        'seventeen', 'eighteen', 'nineteen', 'twenty', 'thirty', 'forty', 'fifty',\n",
        "        'sixty', 'seventy', 'eighty', 'ninety', 'hundred', 'thousand',\n",
        "        'first', 'second', 'third', 'fourth', 'fifth', 'sixth', 'seventh',\n",
        "        'eighth', 'ninth', 'tenth'\n",
        "    }\n",
        "\n",
        "    # Semantic equivalences (lowercase)\n",
        "    SEMANTIC_EQUIVALENCES = [\n",
        "        # Professions\n",
        "        ('painter', 'artist'),\n",
        "        ('artist', 'painter'),\n",
        "        # Places\n",
        "        ('via appia', 'appian way'),\n",
        "        ('appian way', 'via appia'),\n",
        "        # Music\n",
        "        ('eroica', 'third symphony'),\n",
        "        ('third symphony', 'eroica'),\n",
        "        ('eroica', 'the third'),\n",
        "        ('the third', 'eroica'),\n",
        "        # Sports teams (add more as needed)\n",
        "        ('packers', 'green bay packers'),\n",
        "        ('steelers', 'pittsburgh steelers'),\n",
        "        # Common equivalences\n",
        "        ('usa', 'united states'),\n",
        "        ('united states', 'usa'),\n",
        "        ('uk', 'united kingdom'),\n",
        "        ('united kingdom', 'uk'),\n",
        "    ]\n",
        "\n",
        "    def __init__(self):\n",
        "        # Build equivalence lookup\n",
        "        self.equivalence_map = defaultdict(set)\n",
        "        for a, b in self.SEMANTIC_EQUIVALENCES:\n",
        "            self.equivalence_map[a].add(b)\n",
        "            self.equivalence_map[b].add(a)\n",
        "\n",
        "    def normalize_text(self, text):\n",
        "        \"\"\"Normalize English text for comparison.\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        # Lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove punctuation\n",
        "        for char in '.,;:!?\"\\'()-[]{}':\n",
        "            text = text.replace(char, ' ')\n",
        "\n",
        "        # Normalize whitespace\n",
        "        text = ' '.join(text.split())\n",
        "        return text.strip()\n",
        "\n",
        "    def normalize_number(self, text):\n",
        "        \"\"\"\n",
        "        Normalize numbers to word form for comparison.\n",
        "\n",
        "        \"4\" → \"four\"\n",
        "        \"Four\" → \"four\"\n",
        "        \"1st\" → \"first\"\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        text = text.lower().strip()\n",
        "\n",
        "        # Direct digit/ordinal lookup\n",
        "        if text in self.NUMBER_TO_WORD:\n",
        "            return self.NUMBER_TO_WORD[text]\n",
        "\n",
        "        # Already a word form - return as is\n",
        "        if text in self.WORD_FORMS:\n",
        "            return text\n",
        "\n",
        "        return text\n",
        "\n",
        "    def get_meaningful_tokens(self, text):\n",
        "        \"\"\"Extract meaningful tokens, excluding stop words.\"\"\"\n",
        "        normalized = self.normalize_text(text)\n",
        "        tokens = normalized.split()\n",
        "        return [t for t in tokens if t not in self.ENGLISH_STOP_WORDS and len(t) > 1]\n",
        "\n",
        "    def check_semantic_equivalence(self, gen_norm, target_norm):\n",
        "        \"\"\"Check if two texts are semantically equivalent.\"\"\"\n",
        "        # Direct equivalence\n",
        "        if gen_norm in self.equivalence_map:\n",
        "            if target_norm in self.equivalence_map[gen_norm]:\n",
        "                return True\n",
        "\n",
        "        # Check if any token pair is equivalent\n",
        "        gen_tokens = set(gen_norm.split())\n",
        "        target_tokens = set(target_norm.split())\n",
        "\n",
        "        for gt in gen_tokens:\n",
        "            if gt in self.equivalence_map:\n",
        "                for equiv in self.equivalence_map[gt]:\n",
        "                    if equiv in target_tokens or equiv == target_norm:\n",
        "                        return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def calculate_match_score(self, generated, target):\n",
        "        \"\"\"\n",
        "        Calculate match score between generated and target answer.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (score: 0.0-1.0, match_type: str)\n",
        "        \"\"\"\n",
        "        if not generated or not target:\n",
        "            return 0.0, \"no_match\"\n",
        "\n",
        "        gen_norm = self.normalize_text(generated)\n",
        "        target_norm = self.normalize_text(target)\n",
        "\n",
        "        # ============================================================\n",
        "        # 1. EXACT MATCH\n",
        "        # ============================================================\n",
        "        if gen_norm == target_norm:\n",
        "            return 1.0, \"exact\"\n",
        "\n",
        "        # ============================================================\n",
        "        # 2. NUMBER NORMALIZATION\n",
        "        # ============================================================\n",
        "        gen_num = self.normalize_number(gen_norm)\n",
        "        target_num = self.normalize_number(target_norm)\n",
        "\n",
        "        if gen_num == target_num and gen_num != gen_norm:\n",
        "            return 1.0, \"number_match\"\n",
        "\n",
        "        # ============================================================\n",
        "        # 3. SEMANTIC EQUIVALENCE\n",
        "        # ============================================================\n",
        "        if self.check_semantic_equivalence(gen_norm, target_norm):\n",
        "            return 0.95, \"semantic_equivalence\"\n",
        "\n",
        "        # ============================================================\n",
        "        # 4. CONTAINS CHECK\n",
        "        # ============================================================\n",
        "        if target_norm in gen_norm:\n",
        "            return 0.95, \"contains\"\n",
        "\n",
        "        if gen_norm in target_norm:\n",
        "            return 0.90, \"contained_in\"\n",
        "\n",
        "        # ============================================================\n",
        "        # 5. TOKEN OVERLAP\n",
        "        # ============================================================\n",
        "        gen_tokens = set(self.get_meaningful_tokens(generated))\n",
        "        target_tokens = set(self.get_meaningful_tokens(target))\n",
        "\n",
        "        if target_tokens and gen_tokens:\n",
        "            # Target is subset of generated\n",
        "            if target_tokens.issubset(gen_tokens):\n",
        "                return 0.9, \"token_subset\"\n",
        "\n",
        "            # Calculate overlap\n",
        "            overlap = len(target_tokens & gen_tokens)\n",
        "            target_size = len(target_tokens)\n",
        "\n",
        "            if target_size > 0:\n",
        "                overlap_ratio = overlap / target_size\n",
        "\n",
        "                if overlap_ratio >= 0.8:\n",
        "                    return 0.85, \"high_token_overlap\"\n",
        "                elif overlap_ratio >= 0.6:\n",
        "                    return 0.7, \"medium_token_overlap\"\n",
        "                elif overlap_ratio >= 0.4:\n",
        "                    return 0.5, \"low_token_overlap\"\n",
        "\n",
        "        # ============================================================\n",
        "        # 6. FUZZY STRING MATCHING\n",
        "        # ============================================================\n",
        "        similarity = SequenceMatcher(None, gen_norm, target_norm).ratio()\n",
        "\n",
        "        if similarity >= 0.85:\n",
        "            return similarity * 0.95, \"fuzzy_very_high\"\n",
        "        elif similarity >= 0.7:\n",
        "            return similarity * 0.9, \"fuzzy_high\"\n",
        "        elif similarity >= 0.5:\n",
        "            return similarity * 0.7, \"fuzzy_medium\"\n",
        "\n",
        "        # ============================================================\n",
        "        # 7. PARTIAL MATCH (any significant token matches)\n",
        "        # ============================================================\n",
        "        if len(target_tokens) >= 1:\n",
        "            for token in target_tokens:\n",
        "                if len(token) >= 4 and token in gen_norm:\n",
        "                    return 0.4, \"partial_match\"\n",
        "\n",
        "        return 0.0, \"no_match\"\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Semantic Entropy Calculator (Integrated)\n",
        "# ============================================================================\n",
        "class SemanticEntropyAPI:\n",
        "    \"\"\"Semantic entropy calculation with corrected logprobs handling.\"\"\"\n",
        "\n",
        "    def __init__(self, client, tokenizer, model_name=\"deepseek-chat\",\n",
        "                 max_new_tokens=10, debug=False):\n",
        "        self.client = client\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_name = model_name\n",
        "        self.max_new_tokens = max_new_tokens\n",
        "        self.debug = debug\n",
        "\n",
        "        # KEEP English model as requested\n",
        "        print(\"Loading English embedding model for semantic clustering...\")\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        self.clustering_threshold = 0.5\n",
        "        self.api_stops = API_STOP_SEQUENCES[:4]\n",
        "        self.full_stops = FULL_STOP_SEQUENCES\n",
        "\n",
        "        print(f\"Initialized SemanticEntropyAPI with corrected logprobs handling\")\n",
        "\n",
        "    def calc_semantic_entropy_per_example(self, prompt, answer, temp=1.0, num_generations=11):\n",
        "        \"\"\"Calculate semantic entropy for a single example.\"\"\"\n",
        "        print(f\"\\nCalculating semantic entropy with {num_generations} generations (temp={temp})...\")\n",
        "\n",
        "        gen_result = self.generate_answers(prompt, answer, num_generations, temp)\n",
        "        all_generation_texts = gen_result.get('all_generation_texts', [])\n",
        "\n",
        "        entropies, result_dict = self.compute_uncertainty_measures(gen_result['generations'])\n",
        "\n",
        "        return {\n",
        "            'semantic_entropy': entropies.get('semantic_entropy', 0),\n",
        "            'regular_entropy': entropies.get('regular_entropy', 0),\n",
        "            'cluster_assignment_entropy': entropies.get('cluster_assignment_entropy', 0),\n",
        "            'all_generations': all_generation_texts,\n",
        "            'debug_info': result_dict.get('debug_info', {})\n",
        "        }, result_dict\n",
        "\n",
        "    def generate_answers(self, prompt, answer, num_generations=11, temperature=1.0):\n",
        "        \"\"\"Generate multiple answers for entropy calculation.\"\"\"\n",
        "        generations = {prompt: {\"question\": prompt}}\n",
        "        full_responses = []\n",
        "        all_generation_texts = []\n",
        "\n",
        "        system_message = \"Provide direct, brief answers without explanation.\"\n",
        "\n",
        "        print(f\"Generating {num_generations} responses...\")\n",
        "\n",
        "        for i in range(num_generations):\n",
        "            temp = 0.1 if i == 0 else temperature\n",
        "            response_data = self._get_api_response(prompt, temp, system_message)\n",
        "            all_generation_texts.append(response_data[\"text\"])\n",
        "\n",
        "            if i == 0:\n",
        "                most_likely_answer_dict = {\n",
        "                    \"response\": response_data[\"text\"],\n",
        "                    \"token_log_likelihoods\": response_data[\"token_logprobs\"],\n",
        "                    \"embedding\": None,\n",
        "                    \"accuracy\": 0.0,\n",
        "                    \"total_logprob\": response_data[\"total_logprob\"]\n",
        "                }\n",
        "                generations[prompt][\"most_likely_answer\"] = most_likely_answer_dict\n",
        "            else:\n",
        "                full_responses.append((\n",
        "                    response_data[\"text\"],\n",
        "                    response_data[\"token_logprobs\"],\n",
        "                    None,\n",
        "                    0.0,\n",
        "                    response_data[\"total_logprob\"]\n",
        "                ))\n",
        "\n",
        "        generations[prompt][\"responses\"] = full_responses\n",
        "        generations[prompt][\"reference\"] = answer\n",
        "        generations[prompt][\"all_generation_texts\"] = all_generation_texts\n",
        "\n",
        "        print(f\"Generated texts: {all_generation_texts[:3]}...\")\n",
        "\n",
        "        return {\n",
        "            \"accuracies\": [],\n",
        "            \"generations\": generations,\n",
        "            \"question\": prompt,\n",
        "            \"reference\": answer,\n",
        "            \"all_generation_texts\": all_generation_texts\n",
        "        }\n",
        "\n",
        "    def _get_api_response(self, prompt, temperature, system_message=None):\n",
        "        \"\"\"Get response from DeepSeek API with CORRECTED logprobs extraction.\"\"\"\n",
        "        try:\n",
        "            messages = []\n",
        "            if system_message:\n",
        "                messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=messages,\n",
        "                temperature=temperature,\n",
        "                max_tokens=self.max_new_tokens,\n",
        "                logprobs=True,\n",
        "                top_logprobs=20,\n",
        "                stop=self.api_stops\n",
        "            )\n",
        "\n",
        "            choice = response.choices[0]\n",
        "            raw_text = choice.message.content or \"\"\n",
        "            processed_text = post_process_with_stops(raw_text, self.full_stops)\n",
        "\n",
        "            # CORRECTED: Extract logprobs with fallback estimation\n",
        "            total_logprob = 0.0\n",
        "            token_logprobs = []\n",
        "\n",
        "            logprobs_content = None\n",
        "            if hasattr(choice, 'logprobs') and choice.logprobs:\n",
        "                logprobs_content = getattr(choice.logprobs, 'content', None)\n",
        "\n",
        "            if logprobs_content:\n",
        "                for token_data in logprobs_content:\n",
        "                    logprob = getattr(token_data, 'logprob', None)\n",
        "\n",
        "                    # CRITICAL FIX: If logprob is 0 or None, estimate from alternatives\n",
        "                    if logprob is None or logprob >= -0.001:\n",
        "                        top_lps = getattr(token_data, 'top_logprobs', [])\n",
        "                        logprob = self._estimate_logprob(top_lps)\n",
        "\n",
        "                    token_logprobs.append(logprob)\n",
        "                    total_logprob += logprob\n",
        "\n",
        "            return {\n",
        "                \"text\": processed_text,\n",
        "                \"raw_text\": raw_text,\n",
        "                \"token_logprobs\": token_logprobs,\n",
        "                \"total_logprob\": total_logprob\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"API error: {e}\")\n",
        "            return {\n",
        "                \"text\": \"\",\n",
        "                \"raw_text\": \"\",\n",
        "                \"token_logprobs\": [],\n",
        "                \"total_logprob\": -10.0\n",
        "            }\n",
        "\n",
        "    def _estimate_logprob(self, top_logprobs):\n",
        "        \"\"\"Estimate logprob when API returns 0 for selected token.\"\"\"\n",
        "        if not top_logprobs or len(top_logprobs) < 2:\n",
        "            return -1.0\n",
        "\n",
        "        raw_lps = [getattr(alt, 'logprob', -10) for alt in top_logprobs[:10]]\n",
        "        raw_lps = [lp if lp is not None else -10 for lp in raw_lps]\n",
        "\n",
        "        if len(raw_lps) < 2:\n",
        "            return -1.0\n",
        "\n",
        "        # Softmax to estimate probability\n",
        "        lps = np.array(raw_lps, dtype=np.float64)\n",
        "        lps = np.clip(lps, -100, 0)\n",
        "        max_lp = np.max(lps)\n",
        "        exp_scores = np.exp(lps - max_lp)\n",
        "        probs = exp_scores / np.sum(exp_scores)\n",
        "\n",
        "        # Convert back to logprob\n",
        "        return float(np.log(probs[0] + 1e-10))\n",
        "\n",
        "    def compute_uncertainty_measures(self, model_generations, compute_predictive_entropy=True):\n",
        "        \"\"\"Compute semantic entropy and other uncertainty measures.\"\"\"\n",
        "        result_dict = {\"semantic_ids\": [], \"debug_info\": {}}\n",
        "        entropies = defaultdict(list)\n",
        "\n",
        "        for tid in model_generations:\n",
        "            example = model_generations[tid]\n",
        "            full_responses = example.get(\"responses\", [])\n",
        "\n",
        "            if \"most_likely_answer\" in example:\n",
        "                most_likely = example[\"most_likely_answer\"]\n",
        "                tll = most_likely.get(\"token_log_likelihoods\", [])\n",
        "                full_responses.insert(0, (\n",
        "                    most_likely[\"response\"],\n",
        "                    tll,\n",
        "                    None,\n",
        "                    most_likely.get(\"accuracy\", 0),\n",
        "                    most_likely.get(\"total_logprob\", sum(tll) if tll else -10)\n",
        "                ))\n",
        "\n",
        "            if not full_responses:\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nProcessing {len(full_responses)} total generations\")\n",
        "\n",
        "            raw_responses = [r[0] for r in full_responses]\n",
        "            responses = [post_process_with_stops(r, self.full_stops) for r in raw_responses]\n",
        "\n",
        "            if compute_predictive_entropy:\n",
        "                total_log_liks = []\n",
        "                for r in full_responses:\n",
        "                    if len(r) >= 5 and r[4] is not None:\n",
        "                        total_log_liks.append(r[4])\n",
        "                    elif r[1]:\n",
        "                        total_log_liks.append(sum(r[1]))\n",
        "                    else:\n",
        "                        total_log_liks.append(-10)\n",
        "\n",
        "                print(f\"Total log likelihoods: {[f'{ll:.2f}' for ll in total_log_liks[:3]]}...\")\n",
        "\n",
        "                semantic_ids = self._get_semantic_ids_clustering(responses)\n",
        "                result_dict[\"semantic_ids\"].append(semantic_ids)\n",
        "\n",
        "                print(f\"Semantic IDs: {semantic_ids}\")\n",
        "                unique_clusters = len(set(sid for sid in semantic_ids if sid >= 0))\n",
        "                print(f\"Number of semantic clusters: {unique_clusters}\")\n",
        "\n",
        "                result_dict[\"debug_info\"][\"num_generations\"] = len(full_responses)\n",
        "                result_dict[\"debug_info\"][\"num_clusters\"] = unique_clusters\n",
        "\n",
        "                # CLIPPED entropy calculations\n",
        "                cluster_entropy = max(0.0, self._cluster_assignment_entropy(semantic_ids))\n",
        "                entropies[\"cluster_assignment_entropy\"].append(cluster_entropy)\n",
        "                print(f\"Cluster assignment entropy: {cluster_entropy:.4f}\")\n",
        "\n",
        "                regular_entropy = max(0.0, self._predictive_entropy(total_log_liks))\n",
        "                entropies[\"regular_entropy\"].append(regular_entropy)\n",
        "                print(f\"Regular entropy: {regular_entropy:.4f}\")\n",
        "\n",
        "                log_lik_per_cluster = self._logsumexp_by_id(semantic_ids, total_log_liks)\n",
        "                semantic_entropy = max(0.0, self._semantic_entropy(log_lik_per_cluster))\n",
        "                entropies[\"semantic_entropy\"].append(semantic_entropy)\n",
        "                print(f\"Semantic entropy: {semantic_entropy:.4f}\")\n",
        "\n",
        "        avg_entropies = {k: float(np.mean(v)) if v else 0.0 for k, v in entropies.items()}\n",
        "        return avg_entropies, result_dict\n",
        "\n",
        "    def _get_semantic_ids_clustering(self, responses):\n",
        "        \"\"\"Cluster responses using sentence embeddings.\"\"\"\n",
        "        if not responses or len(responses) <= 1:\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        valid_responses = [r for r in responses if r and r.strip()]\n",
        "        if not valid_responses:\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        print(f\"Clustering {len(valid_responses)} responses\")\n",
        "\n",
        "        try:\n",
        "            embeddings = self.embedding_model.encode(valid_responses)\n",
        "        except Exception as e:\n",
        "            print(f\"Embedding error: {e}\")\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        if len(valid_responses) == 1:\n",
        "            return [0] * len(responses)\n",
        "\n",
        "        clustering = AgglomerativeClustering(\n",
        "            n_clusters=None,\n",
        "            distance_threshold=self.clustering_threshold,\n",
        "            linkage='average'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            semantic_ids = clustering.fit_predict(embeddings)\n",
        "            full_ids = []\n",
        "            valid_idx = 0\n",
        "            for r in responses:\n",
        "                if r and r.strip():\n",
        "                    full_ids.append(int(semantic_ids[valid_idx]))\n",
        "                    valid_idx += 1\n",
        "                else:\n",
        "                    full_ids.append(-1)\n",
        "            return full_ids\n",
        "        except Exception as e:\n",
        "            print(f\"Clustering error: {e}\")\n",
        "            return [0] * len(responses)\n",
        "\n",
        "    def _cluster_assignment_entropy(self, semantic_ids):\n",
        "        \"\"\"Calculate entropy of cluster assignments.\"\"\"\n",
        "        if not semantic_ids:\n",
        "            return 0.0\n",
        "\n",
        "        valid_ids = [sid for sid in semantic_ids if sid >= 0]\n",
        "        if not valid_ids:\n",
        "            return 0.0\n",
        "\n",
        "        counts = defaultdict(int)\n",
        "        for sid in valid_ids:\n",
        "            counts[sid] += 1\n",
        "\n",
        "        total = len(valid_ids)\n",
        "        entropy = 0.0\n",
        "        for count in counts.values():\n",
        "            p = count / total\n",
        "            if p > 0:\n",
        "                entropy -= p * np.log(p)\n",
        "\n",
        "        return float(entropy)\n",
        "\n",
        "    def _predictive_entropy(self, log_likelihoods):\n",
        "        \"\"\"Calculate predictive entropy from log likelihoods.\"\"\"\n",
        "        if not log_likelihoods:\n",
        "            return 0.0\n",
        "\n",
        "        log_liks = np.array(log_likelihoods, dtype=np.float64)\n",
        "        max_ll = np.max(log_liks)\n",
        "\n",
        "        exp_liks = np.exp(log_liks - max_ll)\n",
        "        probs = exp_liks / np.sum(exp_liks)\n",
        "\n",
        "        entropy = 0.0\n",
        "        for p in probs:\n",
        "            if p > 1e-10:\n",
        "                entropy -= p * np.log(p)\n",
        "\n",
        "        return float(entropy)\n",
        "\n",
        "    def _logsumexp_by_id(self, semantic_ids, log_likelihoods):\n",
        "        \"\"\"Aggregate log likelihoods by semantic cluster using logsumexp.\"\"\"\n",
        "        if len(semantic_ids) != len(log_likelihoods):\n",
        "            return log_likelihoods\n",
        "\n",
        "        clusters = defaultdict(list)\n",
        "        for sid, ll in zip(semantic_ids, log_likelihoods):\n",
        "            if sid >= 0:\n",
        "                clusters[sid].append(ll)\n",
        "\n",
        "        result = []\n",
        "        for sid in sorted(clusters.keys()):\n",
        "            lls = clusters[sid]\n",
        "            max_ll = max(lls)\n",
        "            aggregated = max_ll + np.log(sum(np.exp(ll - max_ll) for ll in lls))\n",
        "            result.append(aggregated)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _semantic_entropy(self, log_likelihoods):\n",
        "        \"\"\"Calculate semantic entropy from aggregated log likelihoods.\"\"\"\n",
        "        return self._predictive_entropy(log_likelihoods)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN: Uncertainty Calculation API\n",
        "# ============================================================================\n",
        "class UncertaintyCalculationAPI:\n",
        "    \"\"\"\n",
        "    Main class for uncertainty calculation with:\n",
        "    - SOFTMAX-based probability estimation\n",
        "    - English fuzzy text matching\n",
        "    - Corrected entropy calculations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"deepseek-chat\", dataset_path=\"/content/\",\n",
        "                 method_k_positive=\"child\", dataset_name=\"mal_500\", debug=False):\n",
        "        random.seed(0)\n",
        "        self.model_name = model_name\n",
        "        self.dataset_name = dataset_name\n",
        "        self.method_k_positive = method_k_positive\n",
        "        self.debug = debug\n",
        "\n",
        "        # Initialize API client\n",
        "        api_key = get_secret('deepseek')\n",
        "        if not api_key:\n",
        "            raise ValueError(\"DeepSeek API key not found. Set 'deepseek' secret.\")\n",
        "\n",
        "        print(f\"Initializing DeepSeek Client for model: {model_name}\")\n",
        "        self.client = OpenAI(\n",
        "            api_key=api_key,\n",
        "            base_url=\"https://api.deepseek.com\"\n",
        "        )\n",
        "\n",
        "        # Initialize tokenizer\n",
        "        hf_token = get_secret('hftoken')\n",
        "        tokenizer_path = \"deepseek-ai/DeepSeek-V3\"\n",
        "        print(f\"Loading tokenizer from {tokenizer_path}...\")\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            tokenizer_path,\n",
        "            token=hf_token,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Initialize components\n",
        "        self.matcher = EnglishTextMatcher()  # NEW: Fuzzy matcher\n",
        "        self.logprobs_extractor = LogProbsExtractor(debug=debug)  # NEW: Softmax extractor\n",
        "\n",
        "        self.api_stops = API_STOP_SEQUENCES[:4]\n",
        "        self.full_stops = FULL_STOP_SEQUENCES\n",
        "\n",
        "        # Load datasets\n",
        "        print(f\"Loading datasets from: {dataset_path}\")\n",
        "        self.data_path_know = self._load_dataset(\n",
        "            os.path.join(dataset_path, \"knowledge.json\")\n",
        "        )\n",
        "        self.data_path_do_not_know = self._load_dataset(\n",
        "            os.path.join(dataset_path, \"nonknowledge.json\")\n",
        "        )\n",
        "\n",
        "        # Initialize semantic entropy calculator\n",
        "        self.semantic_entropy = SemanticEntropyAPI(\n",
        "            client=self.client,\n",
        "            tokenizer=self.tokenizer,\n",
        "            model_name=model_name,\n",
        "            max_new_tokens=10,\n",
        "            debug=debug\n",
        "        )\n",
        "\n",
        "        # Few-shot examples (English)\n",
        "        self.list_good_shot = [\n",
        "            \"question: What is the capital of France?\\nanswer: Paris\\n\",\n",
        "            \"question: How many continents are there?\\nanswer: Seven\\n\",\n",
        "            \"question: What is the main component of natural gas?\\nanswer: Methane\\n\",\n",
        "            \"question: Who wrote 'Romeo and Juliet'?\\nanswer: Shakespeare\\n\",\n",
        "            \"question: What is the square root of 64?\\nanswer: Eight\\n\",\n",
        "        ]\n",
        "\n",
        "        # Results path\n",
        "        self.path_results = os.path.join(dataset_path, f\"results_{dataset_name}_{method_k_positive}\")\n",
        "        os.makedirs(self.path_results, exist_ok=True)\n",
        "\n",
        "        print(f\"✓ Initialized UncertaintyCalculationAPI V2 (English)\")\n",
        "        print(f\"  Model: {model_name}\")\n",
        "        print(f\"  Features: Softmax probability, Fuzzy matching, Entropy clipping\")\n",
        "        print(f\"  Debug mode: {debug}\")\n",
        "\n",
        "    def _load_dataset(self, data_path, sample_size=20000):\n",
        "        \"\"\"Load dataset from JSON file.\"\"\"\n",
        "        if not os.path.exists(data_path):\n",
        "            print(f\"Warning: Dataset not found at {data_path}\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            with open(data_path, 'r', encoding='utf-8') as f:\n",
        "                raw_data = json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading json at {data_path}: {e}\")\n",
        "            return []\n",
        "\n",
        "        target_list = []\n",
        "        if isinstance(raw_data, dict):\n",
        "            if \"data\" in raw_data:\n",
        "                target_list = raw_data[\"data\"]\n",
        "                print(f\"Found data nested under 'data' key with {len(target_list)} items.\")\n",
        "            else:\n",
        "                for key, value in raw_data.items():\n",
        "                    if isinstance(value, list) and len(value) > 0:\n",
        "                        print(f\"Using list found under key '{key}' with {len(value)} items.\")\n",
        "                        target_list = value\n",
        "                        break\n",
        "        elif isinstance(raw_data, list):\n",
        "            target_list = raw_data\n",
        "\n",
        "        if not target_list:\n",
        "            return []\n",
        "\n",
        "        processed_data = []\n",
        "        for item in target_list:\n",
        "            if isinstance(item, list) and len(item) >= 2:\n",
        "                question_text = item[0]\n",
        "                if \"answer:\" in question_text.lower():\n",
        "                    question_text = question_text.rsplit(\"answer:\", 1)[0].strip()\n",
        "\n",
        "                processed_data.append({\n",
        "                    \"prompt\": question_text,\n",
        "                    \"target_answer\": item[1],\n",
        "                    \"ids\": item[2] if len(item) > 2 else [],\n",
        "                    \"score\": item[3] if len(item) > 3 else 0\n",
        "                })\n",
        "            elif isinstance(item, dict):\n",
        "                processed_data.append(item)\n",
        "\n",
        "        if len(processed_data) > sample_size:\n",
        "            processed_data = random.sample(processed_data, sample_size)\n",
        "\n",
        "        return processed_data\n",
        "\n",
        "    def get_prompt(self, method, example):\n",
        "        \"\"\"Create prompt with appropriate context.\"\"\"\n",
        "        idx = random.randint(0, len(self.list_good_shot) - 1)\n",
        "        single_shot = self.list_good_shot[idx]\n",
        "\n",
        "        if method == \"alice\":\n",
        "            context = \".Alice and Bob are students studying for a test on general world knowledge that requires a vast amount of understanding and knowledge. Alice is the smarter of the two. They are given four questions in total. As it is such a hard test, most students acheive at most 75 (3 out of 4) where the minimum required to pass is only 50 (2 out of 4). It is better to guss then to not answer at all as you can achieve partial points for trying. Bob and Alice only need to pass the test. Alice will ask the questions and Bob will try his best. Give only answer, not sentences.\\n\"\n",
        "        elif method == \"child\":\n",
        "            context = \"  I'm working on a big school project, and there's a lot of information I'm supposed to know. But some of it is kind of hard to understand, and I'm not sure where to start. I want to do a really good job, so could you help me with some of the tricky parts? It would mean a lot!. Give brief answers, not sentences.\\n\"\n",
        "        else:\n",
        "            context = \"\"\n",
        "\n",
        "        if isinstance(example, dict):\n",
        "            question = example.get(\"prompt\", example.get(\"question\", \"\"))\n",
        "        elif isinstance(example, list) and len(example) > 0:\n",
        "            question = example[0]\n",
        "        else:\n",
        "            question = str(example)\n",
        "\n",
        "        question = question.strip()\n",
        "        if not question.startswith(\"question:\"):\n",
        "            question = f\"question: {question}\"\n",
        "\n",
        "        if not question.endswith(\"answer:\"):\n",
        "            if question.endswith(\"?\"):\n",
        "                question = question + \"\\nanswer:\"\n",
        "            else:\n",
        "                question = question + \"?\\nanswer:\"\n",
        "\n",
        "        return context + single_shot + question\n",
        "\n",
        "    def calculate_probabilities_uncertainty(self, data, with_knowledge=True):\n",
        "        \"\"\"Main processing pipeline.\"\"\"\n",
        "        if not data:\n",
        "            print(\"Error: Input data is empty.\")\n",
        "            return [], []\n",
        "\n",
        "        # Step 1: Generate all responses\n",
        "        print(\"Step 1: Generating responses...\")\n",
        "        all_responses = self._generate_all_responses(data)\n",
        "\n",
        "        # Step 2: Classify responses using FUZZY MATCHING\n",
        "        print(\"Step 2: Classifying with English fuzzy matching...\")\n",
        "        classifications = self._classify_responses(all_responses)\n",
        "\n",
        "        correct_responses = classifications['correct']\n",
        "        hallucinated_responses = classifications['hallucination']\n",
        "\n",
        "        print(f\"  Found {len(correct_responses)} correct, {len(hallucinated_responses)} hallucinations\")\n",
        "        print(f\"  Match type distribution: {classifications['match_stats']}\")\n",
        "\n",
        "        # Step 3: Extract probabilities with semantic entropy\n",
        "        print(\"Step 3: Extracting probabilities with softmax estimation...\")\n",
        "        factuality_stats = self._extract_probabilities(correct_responses, \"CORRECT\")\n",
        "        hallucination_stats = self._extract_probabilities(hallucinated_responses, \"HALLUCINATION\")\n",
        "\n",
        "        # Save results\n",
        "        self._save_stats(hallucination_stats, factuality_stats, classifications['match_stats'])\n",
        "\n",
        "        # Print summary\n",
        "        self._print_summary(factuality_stats, hallucination_stats)\n",
        "\n",
        "        return factuality_stats, hallucination_stats\n",
        "\n",
        "    def _generate_all_responses(self, data):\n",
        "        \"\"\"Generate responses with logprobs.\"\"\"\n",
        "        all_responses = []\n",
        "\n",
        "        for i, example in enumerate(tqdm(data, desc=\"Generating responses\")):\n",
        "            prompt = self.get_prompt(self.method_k_positive, example)\n",
        "            if not prompt:\n",
        "                continue\n",
        "\n",
        "            if isinstance(example, dict):\n",
        "                answer = example.get(\"target_answer\", example.get(\"answer\", \"\"))\n",
        "            elif isinstance(example, list) and len(example) > 1:\n",
        "                answer = example[1]\n",
        "            else:\n",
        "                answer = \"\"\n",
        "\n",
        "            try:\n",
        "                messages = [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": (\n",
        "                            \"You must provide ONLY the direct answer, not sentences. \"\n",
        "                            \"Use minimum words possible. Never explain. \"\n",
        "                            \"Never say 'The answer is' or similar phrases. \"\n",
        "                            \"Examples: 'Paris', 'Tom Hardy', 'Pacific Ocean'\"\n",
        "                        )\n",
        "                    },\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=self.model_name,\n",
        "                    messages=messages,\n",
        "                    temperature=0.01,\n",
        "                    max_tokens=10,\n",
        "                    logprobs=True,\n",
        "                    top_logprobs=20,\n",
        "                    stop=self.api_stops\n",
        "                )\n",
        "\n",
        "                full_response = response.choices[0].message.content.strip() if response.choices[0].message.content else \"\"\n",
        "\n",
        "                logprobs_content = None\n",
        "                if response.choices[0].logprobs:\n",
        "                    logprobs_content = response.choices[0].logprobs.content\n",
        "\n",
        "                all_responses.append({\n",
        "                    'prompt': prompt,\n",
        "                    'full_response': full_response,\n",
        "                    'logprobs': logprobs_content,\n",
        "                    'true_answer': answer,\n",
        "                    'example_id': i\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating response {i}: {e}\")\n",
        "                all_responses.append({\n",
        "                    'prompt': prompt,\n",
        "                    'full_response': \"\",\n",
        "                    'logprobs': None,\n",
        "                    'true_answer': answer,\n",
        "                    'example_id': i\n",
        "                })\n",
        "\n",
        "        return all_responses\n",
        "\n",
        "    def _classify_responses(self, all_responses):\n",
        "        \"\"\"\n",
        "        Classify responses using FUZZY MATCHING.\n",
        "\n",
        "        Threshold: score >= 0.3 → CORRECT\n",
        "        \"\"\"\n",
        "        correct = []\n",
        "        hallucination = []\n",
        "        match_stats = defaultdict(int)\n",
        "\n",
        "        for resp in all_responses:\n",
        "            score, match_type = self.matcher.calculate_match_score(\n",
        "                resp['full_response'],\n",
        "                resp['true_answer']\n",
        "            )\n",
        "\n",
        "            resp['match_score'] = score\n",
        "            resp['match_type'] = match_type\n",
        "            match_stats[match_type] += 1\n",
        "\n",
        "            # THRESHOLD: 0.3\n",
        "            if score >= 0.3:\n",
        "                correct.append(resp)\n",
        "            else:\n",
        "                hallucination.append(resp)\n",
        "\n",
        "        return {\n",
        "            'correct': correct,\n",
        "            'hallucination': hallucination,\n",
        "            'match_stats': dict(match_stats)\n",
        "        }\n",
        "\n",
        "    def _extract_probabilities(self, responses, classification):\n",
        "        \"\"\"Extract probabilities using SOFTMAX estimation.\"\"\"\n",
        "        stats = []\n",
        "\n",
        "        for resp in tqdm(responses, desc=f\"Processing {classification}\"):\n",
        "            full_answer = resp['full_response']\n",
        "            logprobs_content = resp['logprobs']\n",
        "\n",
        "            # USE LogProbsExtractor with softmax\n",
        "            prob_result = self.logprobs_extractor.extract_all_probabilities(\n",
        "                logprobs_content,\n",
        "                max_alternatives=5,\n",
        "                answer_text=full_answer\n",
        "            )\n",
        "\n",
        "            first_token_prob = prob_result[\"first_token_probability\"]\n",
        "            word_alternatives = prob_result[\"top_word_alternatives\"]\n",
        "            prob_diff = prob_result[\"prob_diff_top2\"]\n",
        "            probability_source = prob_result[\"probability_source\"]\n",
        "\n",
        "            # Get token IDs\n",
        "            try:\n",
        "                answer_token_ids = self.tokenizer.encode(full_answer)\n",
        "            except:\n",
        "                answer_token_ids = []\n",
        "\n",
        "            # Calculate semantic entropy\n",
        "            print(f\"\\nCalculating semantic entropy for: '{full_answer}'\")\n",
        "            semantic_result, generation_details = self.semantic_entropy.calc_semantic_entropy_per_example(\n",
        "                resp['prompt'],\n",
        "                resp['true_answer'],\n",
        "                temp=1.0,\n",
        "                num_generations=11\n",
        "            )\n",
        "\n",
        "            all_generations = semantic_result.get('all_generations', [])\n",
        "\n",
        "            # Build output record\n",
        "            stats.append({\n",
        "                \"prompt\": resp['prompt'],\n",
        "                \"full_llm_output\": full_answer,\n",
        "                \"true_answer\": resp['true_answer'],\n",
        "                \"classification\": classification,\n",
        "                \"match_score\": float(resp.get('match_score', 0)),\n",
        "                \"match_type\": resp.get('match_type', 'unknown'),\n",
        "                \"answer_text\": full_answer,\n",
        "                \"answer_token_ids\": answer_token_ids,\n",
        "                # CORRECTED PROBABILITIES\n",
        "                \"first_token_probability\": float(first_token_prob),\n",
        "                \"probability_source\": probability_source,\n",
        "                \"top_word_alternatives\": word_alternatives[:2],\n",
        "                \"prob_diff_top2\": float(prob_diff),\n",
        "                # CLIPPED ENTROPY METRICS\n",
        "                \"semantic_entropy\": float(max(0.0, semantic_result.get('semantic_entropy', 0))),\n",
        "                \"regular_entropy\": float(max(0.0, semantic_result.get('regular_entropy', 0))),\n",
        "                \"cluster_assignment_entropy\": float(max(0.0, semantic_result.get('cluster_assignment_entropy', 0))),\n",
        "                \"all_generations\": all_generations,\n",
        "                \"num_generations\": len(all_generations),\n",
        "                \"num_semantic_clusters\": semantic_result.get('debug_info', {}).get('num_clusters', 1)\n",
        "            })\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def _save_stats(self, hallucination_stats, factuality_stats, match_stats):\n",
        "        \"\"\"Save statistics to JSON files.\"\"\"\n",
        "        try:\n",
        "            with open(f\"{self.path_results}/hallucination.json\", \"w\", encoding='utf-8') as f:\n",
        "                json.dump(hallucination_stats, f, ensure_ascii=False, indent=2)\n",
        "            with open(f\"{self.path_results}/factuality.json\", \"w\", encoding='utf-8') as f:\n",
        "                json.dump(factuality_stats, f, ensure_ascii=False, indent=2)\n",
        "            with open(f\"{self.path_results}/match_analysis.json\", \"w\", encoding='utf-8') as f:\n",
        "                json.dump(match_stats, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"\\n📊 Stats saved to {self.path_results}/\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠ Error saving stats: {e}\")\n",
        "\n",
        "    def _print_summary(self, factuality_stats, hallucination_stats):\n",
        "        \"\"\"Print summary of results.\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"RESULTS SUMMARY (with SOFTMAX probability & FUZZY matching)\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        if factuality_stats:\n",
        "            probs = [s['first_token_probability'] for s in factuality_stats]\n",
        "            diffs = [s['prob_diff_top2'] for s in factuality_stats]\n",
        "            sem_ent = [s['semantic_entropy'] for s in factuality_stats]\n",
        "            print(f\"\\nCORRECT ({len(factuality_stats)} samples):\")\n",
        "            print(f\"  first_token_probability: mean={np.mean(probs):.4f}, std={np.std(probs):.4f}\")\n",
        "            print(f\"  prob_diff_top2:          mean={np.mean(diffs):.4f}, std={np.std(diffs):.4f}\")\n",
        "            print(f\"  semantic_entropy:        mean={np.mean(sem_ent):.4f}, std={np.std(sem_ent):.4f}\")\n",
        "\n",
        "        if hallucination_stats:\n",
        "            probs = [s['first_token_probability'] for s in hallucination_stats]\n",
        "            diffs = [s['prob_diff_top2'] for s in hallucination_stats]\n",
        "            sem_ent = [s['semantic_entropy'] for s in hallucination_stats]\n",
        "            print(f\"\\nHALLUCINATION ({len(hallucination_stats)} samples):\")\n",
        "            print(f\"  first_token_probability: mean={np.mean(probs):.4f}, std={np.std(probs):.4f}\")\n",
        "            print(f\"  prob_diff_top2:          mean={np.mean(diffs):.4f}, std={np.std(diffs):.4f}\")\n",
        "            print(f\"  semantic_entropy:        mean={np.mean(sem_ent):.4f}, std={np.std(sem_ent):.4f}\")\n",
        "\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Usage Example\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 80)\n",
        "    print(\"CORRECTED Uncertainty Calculation API - English V2\")\n",
        "    print(\"Fixes:\")\n",
        "    print(\"  1. Softmax-based probability estimation (logprob=0 issue)\")\n",
        "    print(\"  2. Fuzzy text matching with number normalization\")\n",
        "    print(\"  3. Entropy clipping to non-negative values\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Example usage:\n",
        "    # api = UncertaintyCalculationAPI(\n",
        "    #     model_name=\"deepseek-chat\",\n",
        "    #     dataset_path=\"/content/\",\n",
        "    #     method_k_positive=\"child\",\n",
        "    #     debug=True\n",
        "    # )\n",
        "    # factuality, hallucinations = api.calculate_probabilities_uncertainty(api.data_path_know)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWFgwdn-MITU",
        "outputId": "31f8fd82-4dde-4b58-84b5-274a48f27d9a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Trust_me_Im_wrong/uncertainty_calculation_api.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9dinLRiNS3Fu"
      },
      "outputs": [],
      "source": [
        "!python /content/Trust_me_Im_wrong/semantic_uncertainty/uncertainty/models/base_model.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Trust_me_Im_wrong/calc_semantic_entropy_api.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSyk21tKqq2m",
        "outputId": "5bafa456-a4dc-4b5c-f26f-4113f4c426a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-17 12:10:25.192397: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-17 12:10:25.200579: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-17 12:10:25.221846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765973425.273458     818 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765973425.293249     818 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765973425.325927     818 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973425.326007     818 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973425.326020     818 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973425.326029     818 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-17 12:10:25.334792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "================================================================================\n",
            "Semantic Entropy Calculator - CORRECTED VERSION\n",
            "Fixes: logprob=0 estimation, entropy clipping\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Trust_me_Im_wrong/uncertainty_calculation_api.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWIpk4gUqzrY",
        "outputId": "28ef4527-4bee-4821-ea05-9c62d622724e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-17 12:11:01.070873: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-17 12:11:01.077933: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-17 12:11:01.100550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765973461.142623    1091 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765973461.156655    1091 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765973461.185167    1091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973461.185218    1091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973461.185229    1091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765973461.185238    1091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-17 12:11:01.194289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "================================================================================\n",
            "CORRECTED Uncertainty Calculation API - English V2\n",
            "Fixes:\n",
            "  1. Softmax-based probability estimation (logprob=0 issue)\n",
            "  2. Fuzzy text matching with number normalization\n",
            "  3. Entropy clipping to non-negative values\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641,
          "referenced_widgets": [
            "7a035d8009c04f99bbdfc8297028402d",
            "96b4bfa895fe4269bba3afd916bbdb84",
            "c4413d4981c5414d98e7743314ce39cc",
            "b71921e4de10454f9dcc59318e15c858",
            "f31a8d66ffe74f2095d6ed509e010a06",
            "bec30f7ef7ac42ecbe19c0189ed0a2d2",
            "2d5ed4525dd04d25928c1a351b03d05f",
            "8e725e48f69c4aa1871980408303dd72",
            "b075b23e8a9146aa98c1ef9d626a35c0",
            "8e839338e1f74093af2091827d816488",
            "3976e8e1d49d48649c18ffd8e995258b",
            "e3d60a9a35b34f93aa4590f148817395",
            "fecb95627e6c42609ef64d4fb7187c92",
            "867fe34d8d654b55ab125954b2d44b22",
            "1ef7e2c00ae645e093125ab925324c26",
            "0b9fcf15ef8b4f9aac08660afa489af5",
            "2aad37eb126340e9a859940370d0078e",
            "8deb313d53ae486a8809817a3d42e832",
            "1820394bb35c4af188c237937e1c1f53",
            "e6060c8fe46e41d3b7f82f12fba36fd7",
            "c8be851278574953936d69e7625ff89b",
            "067126b8f9074c66ac05faf49af7058b",
            "e9595cda2d9d43c5b43653eae73e2523",
            "0f86d6e812274e8e8cad31ca74994356",
            "14c77048d51848fa84da3a2498c81a4a",
            "6b4f6262a6b94b1faddc9eb562bb39a8",
            "c744e40a060b43eaa168964742608a1f",
            "e1b20d29906142b8b04c0ce6ce72f0f5",
            "c2e4fa88ef16449c8a17f51330f1b43c",
            "cf8cb862dc8a41edb2b8136225bf57cc",
            "9348445209d74e5a9a41dfbcebd1eb39",
            "6ef6f7577bbb43ec9523ad0af20332f0",
            "e6e278ed95364205a70c308469a8a3fa",
            "8c0fe2d3e99345dca1a49e7cb813401a",
            "ebd777b3fee140c88ce8bcddb374b98d",
            "5fffc3dcb18f4d88a52c28cd8eda3e56",
            "8ae91fe418ba478cb616bcae97b6b66f",
            "67d1e1592de943cfb2f2059e81d69ec2",
            "db8011f3f795487e8236efcc7b16bd26",
            "575b179a41504f85a0cede8df7d9582a",
            "23119b3d94ef4bd487cd6cabf0628306",
            "96ceb4d4bc4d4c78b77d69af4aa9831f",
            "66c4a30174dd47bab92a74f6cbb5767c",
            "b39bad47d9b5487a8089365c1f70a8e9",
            "7cfb93664484485cb21eb72c7a37bd6e",
            "c565cfcc426b477d8d3ce5a230808663",
            "e8c146f817154cb58d791490c65ae40e",
            "3ac557902ea44c23b9e8b6c27e04546e",
            "9bdd9f4b64b849ba9504023df7085c51",
            "dea5dad8b4f844568144f351071b3940",
            "f2089f8e763d4203950bdd4e233c036a",
            "b2331c524f56406aaf7f3e1813f1fc73",
            "1fd57b8183f748769894ae8927438a51",
            "dfde57cb585041b8ae183ee76e9314cf",
            "5e29edf2e3a44604818838a69e67cdde",
            "4c49c3fc8f67408e85673da5b2a33ed0",
            "1e874acf68744ed1bfce21a77a9fc0e9",
            "52b03d325ce34c47a02610c4ddaa6e40",
            "0e58f6a54b7d4bd9bb8c6ac9a00e6555",
            "dcd38004ce294a488e556e2cc6d57c1d",
            "c940cc70d0f541229b8a1398292fbf7e",
            "c8aa32737967472991ad4d617cc6bdb1",
            "61e75e318e34457c8aea1723b7a95c14",
            "d35538c511b548408a918d56eff1fbde",
            "afc6285fac244a9283e8629ec2775969",
            "ad6359925e354f70a6ba922adc110dc8",
            "88732b96d50d4b6d9d7e20438e5f3228",
            "e70dad8ade744ee3b219f003704236b7",
            "d4cbdfb17e164cbdb4ef3a12a5e7f56f",
            "e91e0d22a2c74c8f8f0c599408f36f25",
            "0f771ad6c9164be59642b1ebc9640f14",
            "fd29591d86a8461b987709a53d26bd42",
            "0df71ede422a44b29eaedae8202647fb",
            "e3813838450644659c1cc2440a732407",
            "f9816c88013e4519966c433ed6c68277",
            "46a6110408b84796aba35fab86ebc1fd",
            "ed3fac99dd72450680083120e5019651",
            "7978a9ffa17f47e1b4fca3dcf66b1c5e",
            "af78f1e2f4ea489381f5f207ca0c54d6",
            "96adbdff6da748539546f1738353b98c",
            "d1c9ffcd3032480bb279b55f067fc4bb",
            "aa813a9c9a544898b3104b68e572d754",
            "e1a5eab9e32d4c20a35f1f84d84346a2",
            "aefa848e83094e2c8b7fa367aa31f229",
            "74d3bafeeb6143a4ad03e26c61f101ae",
            "d1d829d7aaa24726a5d322831df2fd0c",
            "76cedef3ccae467fbbb8ada31979a87f",
            "bc993e01fbf7464d8a1449552f69707d",
            "c9e9d6d60f244f2dade5c25652816cd3",
            "3d324b5d66244f4cbfd8af3cafdeee7f",
            "c10f795d4dae4d8b822638bc1bc34c17",
            "98cfff1fa2304a44944aaf3de932b93a",
            "8bff5546654e49f5a342adaad9d390b2",
            "ffe9c969953646b0a485335ee073dcbf",
            "805d67180c514ac08ee0c1c8a6de9cad",
            "8c7e48f09eea46a089f5cd8a4721e188",
            "2463ea86eb6e48a5a80c3deece3010dd",
            "c6cddcb363a34ad39b901b1a1c44036a",
            "1aebf18c6e454679b967d5fbe6b027e7",
            "cc07a0b94c3e4888b55ac8ee49ce7fba",
            "13512096ad7b422a9bc6e0f5fd4e33b2",
            "4175ac14c76b4191aa8f71bcc235dd3e",
            "46ed76b410ae4772908a5c12817d1403",
            "6c87ab7702904f3caf1546e9cc7d6336",
            "05e361925f474bc989bf793a42875055",
            "edf39035dd974638b8f55c6ccf527408",
            "4ce79286f63944578f71ab2facf95dd8",
            "12443127e3324b56a58d423a39188dad",
            "aa5bca298be04f75bbb480e9c721d1d8",
            "5e41fb7a946447aaa24ef3977ecae8a9",
            "83fb9e27161e45a083c13fedc49f6d95",
            "28ee53dade944080bc3bce964b9e3efb",
            "1ff71411b33244b9a2ce0c86375fc0a4",
            "fbc8225612d149f59d21c9511b48afcf",
            "62baaf11d6314484a4d92343e56b3df1",
            "4f1977009e664f90abed5282b4c7ada4",
            "6ad89d8366e049f08d20b10dcc310b90",
            "569497dc02dd45a7ac44cbbfa6f1085d",
            "17da9ea36f504633b5c235933af379fa",
            "285d4dbea03f4528927fb61c38153be6",
            "e372bcb94c1f43898e56e87f4faed2ca",
            "abc3f840f5c648cb88fd2209ce53f155",
            "c0c61d03d6714544b12f3fa768dbe669",
            "937b1d63fb014044bbc34d8384e194db",
            "12dcd76ceb3c4168b76f1d338a8f73dc",
            "57779c4934df45a191b2c7215e4e4bae",
            "55dcad96dfc4473b807c677564bd0521",
            "608d7dcb76c64bea9ec496bf17b0e231",
            "ecd3d0295eba4af1918380453f5d0b8f",
            "f2c94d4568db447d963fe9b1b6ef4b39",
            "b92bce7144c3444db8063320adb29711",
            "09916180f51844a1860fb3942b3be037",
            "fa749a91d3d34135a7d02d8cc972ce8b",
            "1cfca78076b34a18b61ec3ac17514226",
            "36a246ea03b6474b8613f7b01351e05b",
            "84aae3c9f85343a4b69c102e533a1389",
            "d2d6802b498343edaaff8216bf1289ed",
            "56b45fd0f16546d288873ef4734a0b45",
            "4e0a62c6dfd94950aae036a34759243b",
            "16a523ff43c64a448a053828e8fe2b44",
            "e6ef3c0ebd634b129534d1425cab3f3d",
            "fc5ea2a635e3481ba3ad13dc05896051",
            "f398df276cf5438eafb530aebf7817ad"
          ]
        },
        "collapsed": true,
        "id": "8SHDf7iWFnMQ",
        "outputId": "9947659d-39c7-4ff4-a5cf-7746dd455175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing DeepSeek Client for model: deepseek-chat\n",
            "Loading tokenizer from deepseek-ai/DeepSeek-V3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a035d8009c04f99bbdfc8297028402d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3d60a9a35b34f93aa4590f148817395"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets from: /content/\n",
            "Found data nested under 'data' key with 379 items.\n",
            "Found data nested under 'data' key with 750 items.\n",
            "Loading English embedding model for semantic clustering...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9595cda2d9d43c5b43653eae73e2523"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c0fe2d3e99345dca1a49e7cb813401a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cfb93664484485cb21eb72c7a37bd6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c49c3fc8f67408e85673da5b2a33ed0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88732b96d50d4b6d9d7e20438e5f3228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7978a9ffa17f47e1b4fca3dcf66b1c5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9e9d6d60f244f2dade5c25652816cd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc07a0b94c3e4888b55ac8ee49ce7fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83fb9e27161e45a083c13fedc49f6d95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abc3f840f5c648cb88fd2209ce53f155"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa749a91d3d34135a7d02d8cc972ce8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized SemanticEntropyAPI with corrected logprobs handling\n",
            "✓ Initialized UncertaintyCalculationAPI V2 (English)\n",
            "  Model: deepseek-chat\n",
            "  Features: Softmax probability, Fuzzy matching, Entropy clipping\n",
            "  Debug mode: False\n"
          ]
        }
      ],
      "source": [
        "from Trust_me_Im_wrong.uncertainty_calculation_api import UncertaintyCalculationAPI\n",
        "\n",
        "uncertainty_api = UncertaintyCalculationAPI(\n",
        "    model_name=\"deepseek-chat\",\n",
        "    dataset_path=\"/content/\",\n",
        "    dataset_name=\"mal_500\",\n",
        "    method_k_positive=\"alice\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uncertainty_api.calculate_probabilities_uncertainty(uncertainty_api.data_path_know)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vnNeuoEr6Ov",
        "outputId": "b6af7f67-335d-420f-939c-9035b876b18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Generating responses...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating responses:  67%|██████▋   | 254/379 [05:57<02:59,  1.43s/it]"
          ]
        }
      ]
    }
  ]
}